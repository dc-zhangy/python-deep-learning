{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¦å­¦ä¹ ä½¿ç”¨è¯å‘é‡æ¥æ„å»ºä¸€ä¸ªè¡¨æƒ…ç”Ÿæˆå™¨ã€‚\n",
    "\n",
    "â€ƒâ€ƒä½ æœ‰æ²¡æœ‰æƒ³è¿‡è®©ä½ çš„æ–‡å­—ä¹Ÿæœ‰æ›´ä¸°å¯Œè¡¨è¾¾èƒ½åŠ›å‘¢ï¼Ÿæ¯”å¦‚å†™ä¸‹â€œCongratulations on the promotion! Lets get coffee and talk. Love you!â€ï¼Œé‚£ä¹ˆä½ çš„è¡¨æƒ…ç”Ÿæˆå™¨å°±ä¼šè‡ªåŠ¨ç”Ÿæˆâ€œCongratulations on the promotion! ğŸ‘ Lets get coffee and talk. â˜•ï¸ Love you! â¤ï¸â€ã€‚\n",
    "\n",
    "â€ƒâ€ƒå¦ä¸€æ–¹é¢ï¼Œå¦‚æœä½ å¯¹è¿™äº›è¡¨æƒ…ä¸æ„Ÿå†’ï¼Œè€Œä½ çš„æœ‹å‹ç»™ä½ å‘äº†ä¸€å¤§å †çš„å¸¦è¡¨æƒ…çš„æ–‡å­—ï¼Œé‚£ä¹ˆä½ ä¹Ÿå¯ä»¥ä½¿ç”¨è¡¨æƒ…ç”Ÿæˆå™¨æ¥æ€¼å›å»ã€‚\n",
    "\n",
    "â€ƒâ€ƒæˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œè¾“å…¥çš„æ˜¯æ–‡å­—ï¼ˆæ¯”å¦‚â€œLetâ€™s go see the baseball game tonight!â€ï¼‰ï¼Œè¾“å‡ºçš„æ˜¯è¡¨æƒ…ï¼ˆâš¾ï¸ï¼‰ã€‚åœ¨ä¼—å¤šçš„Emojiè¡¨æƒ…ä¸­ï¼Œæ¯”å¦‚â€œâ¤ï¸â€ä»£è¡¨çš„æ˜¯â€œå¿ƒâ€è€Œä¸æ˜¯â€œçˆ±â€ï¼Œä½†æ˜¯å¦‚æœä½ ä½¿ç”¨è¯å‘é‡ï¼Œé‚£ä¹ˆä½ ä¼šå‘ç°å³ä½¿ä½ çš„è®­ç»ƒé›†åªæ˜ç¡®åœ°å°†å‡ ä¸ªå•è¯ä¸ç‰¹å®šçš„è¡¨æƒ…ç¬¦å·ç›¸å…³è”ï¼Œä½ çš„æ¨¡å‹ä¹Ÿäº†èƒ½å¤Ÿå°†æµ‹è¯•é›†ä¸­çš„å•è¯å½’çº³ã€æ€»ç»“åˆ°åŒä¸€ä¸ªè¡¨æƒ…ç¬¦å·ï¼Œç”šè‡³æœ‰äº›å•è¯æ²¡æœ‰å‡ºç°åœ¨ä½ çš„è®­ç»ƒé›†ä¸­ä¹Ÿå¯ä»¥ã€‚\n",
    "\n",
    "â€ƒâ€ƒåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å¼€å§‹æ„å»ºä¸€ä¸ªä½¿ç”¨è¯å‘é‡çš„åŸºå‡†æ¨¡å‹ï¼ˆEmojifier-V1ï¼‰ï¼Œç„¶åæˆ‘ä»¬ä¼šæ„å»ºä¸€ä¸ªæ›´å¤æ‚çš„åŒ…å«äº†LSTMçš„æ¨¡å‹ï¼ˆEmojifier-V2ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emo_utils\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŸºå‡†æ¨¡å‹ï¼šEmojifier-V1\n",
    "## æ•°æ®é›†\n",
    "æˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨ï¼Œé¦–å…ˆæ˜¯æ•°æ®é›†ï¼ˆXï¼ŒYï¼‰ï¼š\n",
    "- Xï¼šåŒ…å«äº†127ä¸ªå­—ç¬¦ä¸²ç±»å‹çš„çŸ­å¥\n",
    "- Yï¼šåŒ…å«äº†å¯¹åº”çŸ­å¥çš„æ ‡ç­¾ï¼ˆ0-4ï¼‰\n",
    "<img src=\"images/1.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = emo_utils.read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = emo_utils.read_csv('data/test.csv')\n",
    "\n",
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss you so much â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "index  = 3\n",
    "print(X_train[index], emo_utils.label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojifier-V1çš„ç»“æ„\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¦å®ç°ä¸€ä¸ªå«â€œEmojifier-V1â€çš„åŸºå‡†æ¨¡å‹ã€‚\n",
    "<img src=\"images/2.png\" style=\"width:900px;height:300px;\">\n",
    "æ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€æ®µæ–‡å­—ï¼ˆæ¯”å¦‚â€œl lov youâ€ï¼‰ï¼Œè¾“å‡ºçš„æ˜¯ç»´åº¦ä¸º(1,5)çš„å‘é‡ï¼Œæœ€ååœ¨argmaxå±‚æ‰¾å¯»æœ€å¤§å¯èƒ½æ€§çš„è¾“å‡ºã€‚\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†æˆ‘ä»¬çš„æ ‡ç­¾Y YYè½¬æ¢æˆsoftmaxåˆ†ç±»å™¨æ‰€éœ€è¦çš„æ ¼å¼ï¼Œå³ä»(m,1) è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç (m,5)ï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ç»è¿‡ç¼–ç åçš„æ ·æœ¬ï¼Œå…¶ä¸­Y_ohæŒ‡çš„æ˜¯â€œY-one-hotâ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = emo_utils.convert_to_one_hot(Y_train, C=5)\n",
    "Y_oh_test = emo_utils.convert_to_one_hot(Y_test, C=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®ç°Emojifier-V1\n",
    "ç¬¬ä¸€æ­¥å°±æ˜¯æŠŠè¾“å…¥çš„å¥å­è½¬æ¢ä¸ºè¯å‘é‡ï¼Œç„¶åè·å–å‡å€¼ï¼Œæˆ‘ä»¬ä¾ç„¶ä½¿ç”¨50ç»´çš„è¯åµŒå…¥ï¼Œç°åœ¨æˆ‘ä»¬åŠ è½½è¯åµŒå…¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = emo_utils.read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åŠ è½½äº†ï¼š\n",
    "- word_to_indexï¼šå­—å…¸ç±»å‹çš„è¯æ±‡ï¼ˆ400,001ä¸ªï¼‰ä¸ç´¢å¼•çš„æ˜ å°„ï¼ˆæœ‰æ•ˆèŒƒå›´ï¼š0-400,000ï¼‰\n",
    "- index_to_wordï¼šå­—å…¸ç±»å‹çš„ç´¢å¼•ä¸è¯æ±‡ä¹‹é—´çš„æ˜ å°„ã€‚\n",
    "- word_to_vec_mapï¼šå­—å…¸ç±»å‹çš„è¯æ±‡ä¸å¯¹åº”GloVeå‘é‡çš„æ˜ å°„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å•è¯cucumberå¯¹åº”çš„ç´¢å¼•æ˜¯ï¼š113317\n",
      "ç´¢å¼•113317å¯¹åº”çš„å•è¯æ˜¯ï¼šcucumber\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 113317\n",
    "print(\"å•è¯{0}å¯¹åº”çš„ç´¢å¼•æ˜¯ï¼š{1}\".format(word, word_to_index[word]))\n",
    "print(\"ç´¢å¼•{0}å¯¹åº”çš„å•è¯æ˜¯ï¼š{1}\".format(index, index_to_word[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†å®ç°sentence_to_avg()å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¹‹åˆ†ä¸ºä»¥ä¸‹ä¸¤ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "- æŠŠæ¯ä¸ªå¥å­è½¬æ¢ä¸ºå°å†™ï¼Œç„¶ååˆ†å‰²ä¸ºåˆ—è¡¨ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨X.lower() ä¸ X.split()ã€‚\n",
    "- å¯¹äºå¥å­ä¸­çš„æ¯ä¸€ä¸ªå•è¯ï¼Œè½¬æ¢ä¸ºGloVeå‘é‡ï¼Œç„¶åå¯¹å®ƒä»¬å–å¹³å‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    å°†å¥å­è½¬æ¢ä¸ºå•è¯åˆ—è¡¨ï¼Œæå–å…¶GloVeå‘é‡ï¼Œç„¶åå°†å…¶å¹³å‡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        sentence -- å­—ç¬¦ä¸²ç±»å‹ï¼Œä»Xä¸­è·å–çš„æ ·æœ¬ã€‚\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹ï¼Œå•è¯æ˜ å°„åˆ°50ç»´çš„å‘é‡çš„å­—å…¸\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        avg -- å¯¹å¥å­çš„å‡å€¼ç¼–ç ï¼Œç»´åº¦ä¸º(50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ç¬¬ä¸€æ­¥ï¼šåˆ†å‰²å¥å­ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨ã€‚\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    # åˆå§‹åŒ–å‡å€¼è¯å‘é‡\n",
    "    avg = np.zeros(50,)\n",
    "    \n",
    "    # ç¬¬äºŒæ­¥ï¼šå¯¹è¯å‘é‡å–å¹³å‡ã€‚\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]\n",
    "    avg = np.divide(avg, len(words))\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ç°åœ¨åº”è¯¥å®ç°æ‰€æœ‰çš„æ¨¡å‹ç»“æ„äº†ï¼Œåœ¨ä½¿ç”¨sentence_to_avg()ä¹‹åï¼Œè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±ï¼Œå†è¿›è¡Œåå‘ä¼ æ’­ï¼Œæœ€åå†æ›´æ–°å‚æ•°ã€‚\n",
    "\n",
    "æˆ‘ä»¬æ ¹æ®å›¾2-2å®ç°model()å‡½æ•°ï¼ŒYonæ˜¯å·²ç»ç»è¿‡ç‹¬çƒ­ç¼–ç åçš„Y ï¼Œé‚£ä¹ˆå‰å‘ä¼ æ’­ä»¥åŠè®¡ç®—æŸå¤±çš„å…¬å¼å¦‚ä¸‹ï¼š\n",
    "    $$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate=0.01, num_iterations=400):\n",
    "    \"\"\"\n",
    "    åœ¨numpyä¸­è®­ç»ƒè¯å‘é‡æ¨¡å‹ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        X -- è¾“å…¥çš„å­—ç¬¦ä¸²ç±»å‹çš„æ•°æ®ï¼Œç»´åº¦ä¸º(m, 1)ã€‚\n",
    "        Y -- å¯¹åº”çš„æ ‡ç­¾ï¼Œ0-7çš„æ•°ç»„ï¼Œç»´åº¦ä¸º(m, 1)ã€‚\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹çš„å•è¯åˆ°50ç»´è¯å‘é‡çš„æ˜ å°„ã€‚\n",
    "        learning_rate -- å­¦ä¹ ç‡.\n",
    "        num_iterations -- è¿­ä»£æ¬¡æ•°ã€‚\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        pred -- é¢„æµ‹çš„å‘é‡ï¼Œç»´åº¦ä¸º(m, 1)ã€‚\n",
    "        W -- æƒé‡å‚æ•°ï¼Œç»´åº¦ä¸º(n_y, n_h)ã€‚\n",
    "        b -- åç½®å‚æ•°ï¼Œç»´åº¦ä¸º(n_y,)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # å®šä¹‰è®­ç»ƒæ•°é‡\n",
    "    m = Y.shape[0]\n",
    "    n_y = 5\n",
    "    n_h = 50\n",
    "    \n",
    "    # ä½¿ç”¨Xavieråˆå§‹åŒ–å‚æ•°\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # å°†Yè½¬æ¢æˆç‹¬çƒ­ç¼–ç \n",
    "    Y_oh = emo_utils.convert_to_one_hot(Y, C=n_y)\n",
    "    \n",
    "    # ä¼˜åŒ–å¾ªç¯\n",
    "    for t in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            # è·å–ç¬¬iä¸ªè®­ç»ƒæ ·æœ¬çš„å‡å€¼\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = emo_utils.softmax(z)\n",
    "            \n",
    "            # è®¡ç®—ç¬¬iä¸ªè®­ç»ƒçš„æŸå¤±\n",
    "            cost = -np.sum(Y_oh[i]*np.log(a))\n",
    "            \n",
    "            # è®¡ç®—æ¢¯åº¦\n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "            \n",
    "            # æ›´æ–°å‚æ•°\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        if t % 100 == 0:\n",
    "            print(\"ç¬¬{t}è½®ï¼ŒæŸå¤±ä¸º{cost}\".format(t=t,cost=cost))\n",
    "            pred = emo_utils.predict(X, Y, W, b, word_to_vec_map)\n",
    "            \n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬0è½®ï¼ŒæŸå¤±ä¸º1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "ç¬¬100è½®ï¼ŒæŸå¤±ä¸º0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "ç¬¬200è½®ï¼ŒæŸå¤±ä¸º0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "ç¬¬300è½®ï¼ŒæŸå¤±ä¸º0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====è®­ç»ƒé›†====\n",
      "Accuracy: 0.9772727272727273\n",
      "=====æµ‹è¯•é›†====\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"=====è®­ç»ƒé›†====\")\n",
    "pred_train = emo_utils.predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print(\"=====æµ‹è¯•é›†====\")\n",
    "pred_test = emo_utils.predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‡è®¾æœ‰5ä¸ªç±»åˆ«ï¼ŒéšæœºçŒœæµ‹çš„å‡†ç¡®ç‡åœ¨20%å·¦å³ï¼Œä½†æ˜¯ä»…ä»…ç»è¿‡127ä¸ªæ ·æœ¬çš„è®­ç»ƒï¼Œå°±æœ‰å¾ˆå¥½çš„è¡¨ç°ã€‚åœ¨è®­ç»ƒé›†ä¸­ï¼Œç®—æ³•çœ‹åˆ°äº†â€œI love youâ€çš„å¥å­ï¼Œå…¶æ ‡ç­¾ä¸ºâ€œâ¤ï¸â€ï¼Œåœ¨è®­ç»ƒé›†ä¸­æ²¡æœ‰â€œadoreâ€è¿™ä¸ªè¯æ±‡ï¼Œå¦‚æœæˆ‘ä»¬å†™â€œI adore youâ€ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you â¤ï¸\n",
      "i love you â¤ï¸\n",
      "funny lol ğŸ˜„\n",
      "lets play with a ball âš¾\n",
      "food is ready ğŸ´\n",
      "you are not happy â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"you are not happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = emo_utils.predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "emo_utils.print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®Œæˆäº†è¿™ä¸€éƒ¨åˆ†ä¹‹åï¼Œä½ éœ€è¦è®°ä½çš„æ˜¯ï¼š\n",
    "- å³ä½¿ä½ åªæœ‰128ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½ ä¹Ÿå¯ä»¥å¾—åˆ°å¾ˆå¥½åœ°è¡¨æƒ…ç¬¦å·æ¨¡å‹ï¼Œå› ä¸ºè¯å‘é‡æ˜¯è®­ç»ƒå¥½äº†çš„ï¼Œå®ƒä¼šç»™ä½ ä¸€ä¸ªè¾ƒå¥½çš„æ¦‚æ‹¬èƒ½åŠ›ã€‚\n",
    "- Emojifier-V1æ˜¯æœ‰ç¼ºé™·çš„ï¼Œæ¯”å¦‚å®ƒä¸ä¼šæŠŠâ€œThis movie is not good and not enjoyableâ€åˆ’åˆ†ä¸ºä¸å¥½ä¸€ç±»ï¼Œå› ä¸ºå®ƒåªæ˜¯å°†æ‰€æœ‰å•è¯çš„å‘é‡åšäº†å¹³å‡ï¼Œæ²¡æœ‰å…³å¿ƒè¿‡é¡ºåºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojifier-V2ï¼šåœ¨Kerasä¸­ä½¿ç”¨LSTMæ¨¡å—\n",
    "ç°åœ¨æˆ‘ä»¬æ„å»ºä¸€ä¸ªèƒ½å¤Ÿæ¥å—è¾“å…¥æ–‡å­—åºåˆ—çš„æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ä¼šè€ƒè™‘åˆ°æ–‡å­—çš„é¡ºåºã€‚Emojifier-V2ä¾ç„¶ä¼šä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„è¯åµŒå…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1)\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹é¢„è§ˆ\n",
    "æˆ‘ä»¬å°†å®ç°ä¸‹é¢è¿™ä¸€ä¸ªæ¨¡å‹\n",
    "<img src=\"images/3.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasä¸mini-batching\n",
    "åœ¨è¿™ä¸ªéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨mini-batchesæ¥è®­ç»ƒKerasæ¨¡å‹ï¼Œä½†æ˜¯å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ æ¡†æ¶éœ€è¦ä½¿ç”¨ç›¸åŒçš„é•¿åº¦çš„æ–‡å­—ï¼Œè¿™æ˜¯å› ä¸ºå¦‚æœä½ ä½¿ç”¨3ä¸ªå•è¯ä¸4ä¸ªå•è¯çš„å¥å­ï¼Œé‚£ä¹ˆè½¬åŒ–ä¸ºå‘é‡ä¹‹åï¼Œè®¡ç®—æ­¥éª¤å°±æœ‰æ‰€ä¸åŒï¼ˆä¸€ä¸ªæ˜¯éœ€è¦3ä¸ªLSTMï¼Œå¦ä¸€ä¸ªéœ€è¦4ä¸ªLSTMï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸å¯èƒ½å¯¹è¿™äº›å¥å­è¿›è¡ŒåŒæ—¶è®­ç»ƒã€‚\n",
    "\n",
    "é‚£ä¹ˆé€šç”¨çš„è§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨å¡«å……ã€‚æŒ‡å®šæœ€é•¿å¥å­çš„é•¿åº¦ï¼Œç„¶åå¯¹å…¶ä»–å¥å­è¿›è¡Œå¡«å……åˆ°ç›¸åŒé•¿åº¦ã€‚æ¯”å¦‚ï¼šæŒ‡å®šæœ€å¤§çš„å¥å­çš„é•¿åº¦ä¸º20ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ¯ä¸ªå¥å­ä½¿ç”¨â€œ0â€æ¥å¡«å……ï¼Œç›´åˆ°å¥å­é•¿åº¦ä¸º20ï¼Œå› æ­¤ï¼Œå¥å­â€œI love youâ€å°±å¯ä»¥è¡¨ç¤ºä¸º$(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä»»ä½•ä»»ä½•ä¸€ä¸ªè¶…è¿‡20ä¸ªå•è¯çš„å¥å­å°†è¢«æˆªå–ï¼Œæ‰€ä»¥ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„æ–¹å¼å°±æ˜¯æ‰¾åˆ°æœ€é•¿å¥å­ï¼Œè·å–å®ƒçš„é•¿åº¦ï¼Œç„¶åæŒ‡å®šå®ƒçš„é•¿åº¦ä¸ºæœ€é•¿å¥å­çš„é•¿åº¦ã€‚\n",
    "## åµŒå…¥å±‚ï¼ˆ The Embedding layerï¼‰\n",
    "åœ¨kerasé‡Œé¢ï¼ŒåµŒå…¥çŸ©é˜µè¢«è¡¨ç¤ºä¸ºâ€œlayerâ€ï¼Œå¹¶å°†æ­£æ•´æ•°ï¼ˆå¯¹åº”å•è¯çš„ç´¢å¼•ï¼‰æ˜ å°„åˆ°å›ºå®šå¤§å°çš„Denseå‘é‡ï¼ˆè¯åµŒå…¥å‘é‡ï¼‰ï¼Œå®ƒå¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„è¯åµŒå…¥æ¥æ¥ç€è®­ç»ƒæˆ–è€…ç›´æ¥åˆå§‹åŒ–ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•åœ¨Kerasä¸­åˆ›å»ºä¸€ä¸ªEmbedding()å±‚ï¼Œç„¶åä½¿ç”¨Gloveçš„50ç»´å‘é‡æ¥åˆå§‹åŒ–ã€‚å› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†å¾ˆå°ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ä¼šæ›´æ–°è¯åµŒå…¥ï¼Œè€Œæ˜¯ä¼šä¿ç•™è¯åµŒå…¥çš„å€¼ã€‚\n",
    "åœ¨Embedding()å±‚ä¸­ï¼Œè¾“å…¥ä¸€ä¸ªæ•´æ•°çŸ©é˜µï¼ˆbatchçš„å¤§å°ï¼Œæœ€å¤§çš„è¾“å…¥é•¿åº¦ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹ä¸‹å›¾ï¼š\n",
    "<img src=\"4.png\" style=\"width:700px;height:250px;\">\n",
    "è¿™ä¸ªä¾‹å­å±•ç¤ºäº†ä¸¤ä¸ªæ ·æœ¬é€šè¿‡embeddingå±‚ï¼Œä¸¤ä¸ªæ ·æœ¬éƒ½ç»è¿‡äº†`max_len=5`çš„å¡«å……å¤„ç†ï¼Œæœ€ç»ˆçš„ç»´åº¦å°±å˜æˆäº†`(2, max_len, 50)`ï¼Œè¿™æ˜¯å› ä¸ºä½¿ç”¨äº†50ç»´çš„è¯åµŒå…¥ã€‚\n",
    "\n",
    "ç¬¬ä¸€æ­¥å°±æ˜¯æŠŠæ‰€æœ‰çš„è¦è®­ç»ƒçš„å¥å­è½¬æ¢æˆç´¢å¼•åˆ—è¡¨ï¼Œç„¶åå¯¹è¿™äº›åˆ—è¡¨ä½¿ç”¨0å¡«å……ï¼Œç›´åˆ°åˆ—è¡¨é•¿åº¦ä¸ºæœ€é•¿å¥å­çš„é•¿åº¦ã€‚\n",
    "\n",
    "â€ƒâ€ƒæˆ‘ä»¬å…ˆæ¥å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥çš„æ˜¯Xï¼ˆå­—ç¬¦ä¸²ç±»å‹çš„å¥å­çš„æ•°ç»„ï¼‰ï¼Œå†è½¬åŒ–ä¸ºå¯¹åº”çš„å¥å­åˆ—è¡¨ï¼Œè¾“å‡ºçš„æ˜¯èƒ½å¤Ÿè®©Embedding()å‡½æ•°æ¥å—çš„åˆ—è¡¨æˆ–çŸ©é˜µï¼ˆå‚è§å›¾2-4ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    è¾“å…¥çš„æ˜¯Xï¼ˆå­—ç¬¦ä¸²ç±»å‹çš„å¥å­çš„æ•°ç»„ï¼‰ï¼Œå†è½¬åŒ–ä¸ºå¯¹åº”çš„å¥å­åˆ—è¡¨ï¼Œ\n",
    "    è¾“å‡ºçš„æ˜¯èƒ½å¤Ÿè®©Embedding()å‡½æ•°æ¥å—çš„åˆ—è¡¨æˆ–çŸ©é˜µï¼ˆå‚è§å›¾4ï¼‰ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        X -- å¥å­æ•°ç»„ï¼Œç»´åº¦ä¸º(m, 1)\n",
    "        word_to_index -- å­—å…¸ç±»å‹çš„å•è¯åˆ°ç´¢å¼•çš„æ˜ å°„\n",
    "        max_len -- æœ€å¤§å¥å­çš„é•¿åº¦ï¼Œæ•°æ®é›†ä¸­æ‰€æœ‰çš„å¥å­çš„é•¿åº¦éƒ½ä¸ä¼šè¶…è¿‡å®ƒã€‚\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        X_indices -- å¯¹åº”äºXä¸­çš„å•è¯ç´¢å¼•æ•°ç»„ï¼Œç»´åº¦ä¸º(m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]  # è®­ç»ƒé›†æ•°é‡\n",
    "    # ä½¿ç”¨0åˆå§‹åŒ–X_indices\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "        # å°†ç¬¬iä¸ªå¥å­è½¬åŒ–ä¸ºå°å†™å¹¶æŒ‰å•è¯åˆ†å¼€ã€‚\n",
    "        sentences_words = X[i].lower().split()\n",
    "        \n",
    "        # åˆå§‹åŒ–jä¸º0\n",
    "        j = 0\n",
    "        \n",
    "        # éå†è¿™ä¸ªå•è¯åˆ—è¡¨\n",
    "        for w in sentences_words:\n",
    "            # å°†X_indicesçš„ç¬¬(i, j)å·å…ƒç´ ä¸ºå¯¹åº”çš„å•è¯ç´¢å¼•\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            \n",
    "            j += 1\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å°±åœ¨Kerasä¸­æ„å»ºEmbedding()å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å·²ç»è®­ç»ƒå¥½äº†çš„è¯å‘é‡ï¼Œåœ¨æ„å»ºä¹‹åï¼Œä½¿ç”¨sentences_to_indices()ç”Ÿæˆçš„æ•°æ®ä½œä¸ºè¾“å…¥ï¼ŒEmbedding()å±‚å°†è¿”å›æ¯ä¸ªå¥å­çš„è¯åµŒå…¥ã€‚\n",
    "\n",
    "æˆ‘ä»¬ç°åœ¨å°±å®ç°pretrained_embedding_layer()å‡½æ•°ï¼Œå®ƒå¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n",
    "- ä½¿ç”¨0æ¥åˆå§‹åŒ–åµŒå…¥çŸ©é˜µã€‚\n",
    "- ä½¿ç”¨word_to_vec_mapæ¥å°†è¯åµŒå…¥çŸ©é˜µå¡«å……è¿›åµŒå…¥çŸ©é˜µã€‚\n",
    "- åœ¨Kerasä¸­å®šä¹‰åµŒå…¥å±‚ï¼Œå½“è°ƒç”¨Embedding()çš„æ—¶å€™éœ€è¦è®©è¿™ä¸€å±‚çš„å‚æ•°ä¸èƒ½è¢«è®­ç»ƒï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è®¾ç½®trainable=Falseã€‚\n",
    "- å°†è¯åµŒå…¥çš„æƒå€¼è®¾ç½®ä¸ºè¯åµŒå…¥çš„å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºKeras Embedding()å±‚ï¼ŒåŠ è½½å·²ç»è®­ç»ƒå¥½äº†çš„50ç»´GloVeå‘é‡\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹çš„å•è¯ä¸è¯åµŒå…¥çš„æ˜ å°„\n",
    "        word_to_index -- å­—å…¸ç±»å‹çš„å•è¯åˆ°è¯æ±‡è¡¨ï¼ˆ400,001ä¸ªå•è¯ï¼‰çš„ç´¢å¼•çš„æ˜ å°„ã€‚\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        embedding_layer() -- è®­ç»ƒå¥½äº†çš„Kerasçš„å®ä½“å±‚ã€‚\n",
    "    \"\"\"\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    \n",
    "    # åˆå§‹åŒ–åµŒå…¥çŸ©é˜µ\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # å°†åµŒå…¥çŸ©é˜µçš„æ¯è¡Œçš„â€œindexâ€è®¾ç½®ä¸ºè¯æ±‡â€œindexâ€çš„è¯å‘é‡è¡¨ç¤º\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    \n",
    "    # å®šä¹‰Kerasçš„embbedingå±‚\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    \n",
    "    # æ„å»ºembeddingå±‚ã€‚\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # å°†åµŒå…¥å±‚çš„æƒé‡è®¾ç½®ä¸ºåµŒå…¥çŸ©é˜µã€‚\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„å»ºEmojifier-V2\n",
    "ç°åœ¨æˆ‘ä»¬å¼€å§‹æ„å»ºEmojifier-V2æ¨¡å‹ã€‚embeddingå±‚æˆ‘ä»¬å·²ç»æ„å»ºå®Œæˆäº†ï¼Œç°åœ¨æˆ‘ä»¬å°†å®ƒçš„è¾“å‡ºè¾“å…¥åˆ°LSTMä¸­ã€‚\n",
    "<img src=\"5.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    å®ç°Emojify-V2æ¨¡å‹çš„è®¡ç®—å›¾\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        input_shape -- è¾“å…¥çš„ç»´åº¦ï¼Œé€šå¸¸æ˜¯(max_len,)\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹çš„å•è¯ä¸è¯åµŒå…¥çš„æ˜ å°„ã€‚\n",
    "        word_to_index -- å­—å…¸ç±»å‹çš„å•è¯åˆ°è¯æ±‡è¡¨ï¼ˆ400,001ä¸ªå•è¯ï¼‰çš„ç´¢å¼•çš„æ˜ å°„ã€‚\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        model -- Kerasæ¨¡å‹å®ä½“\n",
    "    \"\"\"\n",
    "    # å®šä¹‰sentence_indicesä¸ºè®¡ç®—å›¾çš„è¾“å…¥ï¼Œç»´åº¦ä¸º(input_shape,)ï¼Œç±»å‹ä¸ºdtype 'int32' \n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # åˆ›å»ºembeddingå±‚\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    # é€šè¿‡åµŒå…¥å±‚ä¼ æ’­sentence_indicesï¼Œä½ ä¼šå¾—åˆ°åµŒå…¥çš„ç»“æœ\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    \n",
    "    # é€šè¿‡å¸¦æœ‰128ç»´éšè—çŠ¶æ€çš„LSTMå±‚ä¼ æ’­åµŒå…¥\n",
    "    # éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿”å›çš„è¾“å‡ºåº”è¯¥æ˜¯ä¸€æ‰¹åºåˆ—ã€‚\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    # ä½¿ç”¨dropoutï¼Œæ¦‚ç‡ä¸º0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # é€šè¿‡å¦ä¸€ä¸ª128ç»´éšè—çŠ¶æ€çš„LSTMå±‚ä¼ æ’­X\n",
    "    # æ³¨æ„ï¼Œè¿”å›çš„è¾“å‡ºåº”è¯¥æ˜¯å•ä¸ªéšè—çŠ¶æ€ï¼Œè€Œä¸æ˜¯ä¸€ç»„åºåˆ—ã€‚\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    # ä½¿ç”¨dropoutï¼Œæ¦‚ç‡ä¸º0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # é€šè¿‡softmaxæ¿€æ´»çš„Denseå±‚ä¼ æ’­Xï¼Œå¾—åˆ°ä¸€æ‰¹5ç»´å‘é‡ã€‚\n",
    "    X = Dense(5)(X)\n",
    "    # æ·»åŠ softmaxæ¿€æ´»\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹å®ä½“\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºæ•°æ®é›†ä¸­æ‰€æœ‰å¥å­éƒ½å°äº10ä¸ªå•è¯ï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰æ‹©max_len=10ã€‚åœ¨æ¥ä¸‹æ¥çš„ä»£ç ä¸­ï¼Œä½ åº”è¯¥å¯ä»¥çœ‹åˆ°æœ‰â€œ20,223,927â€ä¸ªå‚æ•°ï¼Œå…¶ä¸­â€œ20,000,050â€ä¸ªå‚æ•°æ²¡æœ‰è¢«è®­ç»ƒï¼ˆè¿™æ˜¯å› ä¸ºå®ƒæ˜¯è¯å‘é‡ï¼‰ï¼Œå‰©ä¸‹çš„æ˜¯æœ‰â€œ223,877â€è¢«è®­ç»ƒäº†çš„ã€‚å› ä¸ºæˆ‘ä»¬çš„å•è¯è¡¨æœ‰400,001ä¸ªå•è¯ï¼Œæ‰€ä»¥æ˜¯400,001âˆ—50=20,000,050 ä¸ªä¸å¯è®­ç»ƒçš„å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((10,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = emo_utils.convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 7s 57ms/step - loss: 1.6083 - acc: 0.1970\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.5324 - acc: 0.2955\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.5011 - acc: 0.3258\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4391 - acc: 0.3561\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3480 - acc: 0.4545\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.2345 - acc: 0.5152\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.1767 - acc: 0.4470\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.0551 - acc: 0.5758\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8772 - acc: 0.7121\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8227 - acc: 0.6970\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.7030 - acc: 0.7500\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5999 - acc: 0.8030\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4925 - acc: 0.8333\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5097 - acc: 0.8333\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4789 - acc: 0.8258\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3543 - acc: 0.8636\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3910 - acc: 0.8561\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6488 - acc: 0.8106\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5177 - acc: 0.8182\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3954 - acc: 0.8409\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4705 - acc: 0.8182\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3883 - acc: 0.8636\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3783 - acc: 0.8561\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3052 - acc: 0.9091\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3477 - acc: 0.8864\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2418 - acc: 0.9394\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3171 - acc: 0.8788\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2404 - acc: 0.9318\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3936 - acc: 0.8712\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2669 - acc: 0.9091\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2952 - acc: 0.8864\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2034 - acc: 0.9318\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2117 - acc: 0.9470\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1577 - acc: 0.9621\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.9621\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1889 - acc: 0.9394A: 0s - loss: 0.2063 - acc: 0.927\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1792 - acc: 0.9394\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2159 - acc: 0.9394\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1399 - acc: 0.9621\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1548 - acc: 0.9545\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0870 - acc: 0.9848\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9773\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0806 - acc: 0.9848\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0495 - acc: 0.9924\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0782 - acc: 0.9848\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9773\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1453 - acc: 0.9470\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3145 - acc: 0.9242\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1128 - acc: 0.9848\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1712 - acc: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2009dc92e48>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 9ms/step\n",
      "Test accuracy =  0.8214285629136222\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = emo_utils.convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜„   é¢„æµ‹ç»“æœï¼š she got me a nice present\tâ¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜   é¢„æµ‹ç»“æœï¼š work is hard\tğŸ˜„\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜   é¢„æµ‹ç»“æœï¼š This girl is messing with me\tâ¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ´   é¢„æµ‹ç»“æœï¼š any suggestions for dinner\tğŸ˜„\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šâ¤ï¸   é¢„æµ‹ç»“æœï¼š I love taking breaks\tğŸ˜\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜„   é¢„æµ‹ç»“æœï¼š you brighten my day\tâ¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜„   é¢„æµ‹ç»“æœï¼š will you be my valentine\tâ¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ´   é¢„æµ‹ç»“æœï¼š See you at the restaurant\tğŸ˜„\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ˜   é¢„æµ‹ç»“æœï¼š go away\tâš¾\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ´   é¢„æµ‹ç»“æœï¼š I did not have breakfast â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('æ­£ç¡®è¡¨æƒ…ï¼š'+ emo_utils.label_to_emoji(Y_test[i]) + '   é¢„æµ‹ç»“æœï¼š '+ X_test[i] + emo_utils.label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are so beautiful â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "#å¯ä»¥è¯•è¯•è‡ªå·±å†™ä¸€äº›è¯æ¥é¢„æµ‹\n",
    "x_test = np.array(['you are so beautiful'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  emo_utils.label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are so lucky ğŸ˜\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['you are so lucky'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  emo_utils.label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are so nice â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['you are so nice'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  emo_utils.label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Emoji generator",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
