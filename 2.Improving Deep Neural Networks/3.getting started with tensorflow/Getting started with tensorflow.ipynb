{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow常见函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import tf_utils\n",
    "import time\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(36,name=\"y_hat\")            #定义y_hat为固定值36\n",
    "y = tf.constant(39,name=\"y\")                    #定义y为固定值39\n",
    "loss = tf.Variable((y-y_hat)**2,name=\"loss\" )   #为损失函数创建一个变量\n",
    "\n",
    "init = tf.global_variables_initializer()        #运行之后的初始化(session.run(init))  #损失变量将被初始化并准备计算\n",
    "session=tf.Session()                #创建一个session并打印输出\n",
    "session.run(init)                           #初始化变量\n",
    "print(session.run(loss))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Tensorflow的代码实现而言，实现代码的结构如下：\n",
    "\n",
    "1. 创建Tensorflow变量（此时，尚未直接计算）\n",
    "\n",
    "2. 实现Tensorflow变量之间的操作定义\n",
    "\n",
    "3. 初始化Tensorflow变量\n",
    "\n",
    "4. 创建Session\n",
    "\n",
    "5. 运行Session，此时，之前编写操作都会在这一步运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)\n",
    "#此时并没有计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))\n",
    "#这时才计算了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 占位符\n",
    "占位符（placeholders）一个对象，它的值只能在稍后指定，要指定占位符的值，可以使用一个feed字典（feed_dict变量）来传入，接下来，我们为x创建一个占位符，这将允许我们在稍后运行会话时传入一个数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int64,name=\"x\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(2 * x,feed_dict={x:3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    \"\"\"\n",
    "    实现一个线性功能：\n",
    "        初始化W，类型为tensor的随机变量，维度为(4,3)\n",
    "        初始化X，类型为tensor的随机变量，维度为(3,1)\n",
    "        初始化b，类型为tensor的随机变量，维度为(4,1)\n",
    "    返回：\n",
    "        result - 运行了session后的结果，运行的是Y = WX + b \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1) #指定随机种子\n",
    "\n",
    "    X = np.random.randn(3,1)\n",
    "    W = np.random.randn(4,3)\n",
    "    b = np.random.randn(4,1)\n",
    "\n",
    "    Y = tf.add(tf.matmul(W,X),b) #tf.matmul是矩阵乘法\n",
    "    #Y = tf.matmul(W,X) + b #也可以写成这样子\n",
    "\n",
    "    #创建一个session并运行它\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "\n",
    "    #session使用完毕，关闭它\n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print(\"result = \" +  str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    x = tf.placeholder(tf.float32,name=\"x\")\n",
    "\n",
    "    #计算sigmoid(z)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    #创建一个会话，使用方法二\n",
    "    sess= tf.Session() \n",
    "    result = sess.run(sigmoid,feed_dict={x:z})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.9999938\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算成本\n",
    "\n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{2}$$\n",
    "实现成本函数，需要用到的是:\n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(logits, labels):\n",
    " \n",
    "    z = tf.placeholder(tf.float32, name = \"logits\")\n",
    "    y = tf.placeholder(tf.float32, name = \"labels\")\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z,  labels = y)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    cost = sess.run(cost,feed_dict = {z:logits,y:labels})\n",
    "    sess.close()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [1.0053872  1.0366408  0.41385433 0.39956617]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 独热编码（0、1编码,softmax回归）\n",
    "<img src=\"20180417110137252.png\" style=\"width:600px;height:150px;\">\n",
    "使用代码: \n",
    "- tf.one_hot(labels, depth, axis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(lables,C):\n",
    "    \"\"\"\n",
    "    创建一个矩阵，其中第i行对应第i个类号，第j列对应第j个训练样本\n",
    "    所以如果第j个样本对应着第i个标签，那么entry (i,j)将会是1\n",
    "\n",
    "    参数：\n",
    "        lables - 标签向量\n",
    "        C - 分类数\n",
    "\n",
    "    返回：\n",
    "        one_hot - 独热矩阵\n",
    "    \"\"\"\n",
    "    #创建一个tf.constant，赋值为C，名字叫C\n",
    "    C = tf.constant(C,name=\"C\")\n",
    "\n",
    "    #使用tf.one_hot，注意一下axis\n",
    "    one_hot_matrix = tf.one_hot(indices=lables , depth=C , axis=0)\n",
    "\n",
    "   \n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels,C=4)\n",
    "print(str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化为0和1\n",
    "用到tf.ones()和tf.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(shape):\n",
    "    #使用tf.ones()\n",
    "    ones = tf.ones(shape)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    ones = sess.run(ones)\n",
    "    sess.close()\n",
    "\n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TensorFlow构建神经网络\n",
    "使用TensorFlow构建一个神经网络，需要记住的是实现模型需要做以下两个步骤： \n",
    "1. 创建计算图 \n",
    "2. 运行计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  要解决的问题\n",
    "  一天下午，我们和一些朋友决定教我们的电脑破译手语。我们花了几个小时在白色的墙壁前拍照，于是就有了了以下数据集。现在，你的任务是建立一个算法，使有语音障碍的人与不懂手语的人交流。\n",
    "\n",
    "训练集：有从0到5的数字的1080张图片(64x64像素)，每个数字拥有180张图片。\n",
    "测试集：有从0到5的数字的120张图片(64x64像素)，每个数字拥有5张图片。\n",
    "\n",
    "- **训练集**: 有从0到5的数字的1080张图片(64x64像素)，每个数字拥有180张图片.\n",
    "- **测试集**: 有从0到5的数字的120张图片(64x64像素)，每个数字拥有20张图片.\n",
    "- 目前的模型是：LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX，SIGMOID输出层已经转换为SOFTMAX。当有两个以上的类时，一个SOFTMAX层将SIGMOID一般化\n",
    "需要注意的是这是完整数据集的一个子集，完整的数据集包含更多的符号。\n",
    "\n",
    "下面是每个数字的样本，以及我们如何表示标签的解释。这些都是原始图片，我们实际上用的是64 * 64像素的图片。\n",
    "<img src=\"20180417110431384.png\" style=\"width:800px;height:350px;\"><caption><center> <u><font color='purple'> **Figure 1**</u><font "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1080, 64, 64, 3), (1, 1080))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig , Y_train_orig , X_test_orig , Y_test_orig , classes = tf_utils.load_dataset()\n",
    "X_train_orig.shape , Y_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "plt.imshow(X_train_orig[index])\n",
    "print(\"Y = \" + str(np.squeeze(Y_train_orig[:,index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数 = 1080\n",
      "测试集样本数 = 120\n",
      "X_train.shape: (12288, 1080)\n",
      "Y_train.shape: (6, 1080)\n",
      "X_test.shape: (12288, 120)\n",
      "Y_test.shape: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0],-1).T #每一列就是一个样本\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0],-1).T\n",
    "\n",
    "#归一化数据\n",
    "X_train = X_train_flatten / 255\n",
    "X_test = X_test_flatten / 255\n",
    "\n",
    "#转换为独热矩阵\n",
    "Y_train = tf_utils.convert_to_one_hot(Y_train_orig,6)\n",
    "Y_test = tf_utils.convert_to_one_hot(Y_test_orig,6)\n",
    "\n",
    "print(\"训练集样本数 = \" + str(X_train.shape[1]))\n",
    "print(\"测试集样本数 = \" + str(X_test.shape[1]))\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"Y_train.shape: \" + str(Y_train.shape))\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"Y_test.shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    \"\"\"\n",
    "    为TensorFlow会话创建占位符\n",
    "    参数：\n",
    "        n_x - 一个实数，图片向量的大小（64*64*3 = 12288）\n",
    "        n_y - 一个实数，分类数（从0到5，所以n_y = 6）\n",
    "\n",
    "    返回：\n",
    "        X - 一个数据输入的占位符，维度为[n_x, None]，dtype = \"float\"\n",
    "        Y - 一个对应输入的标签的占位符，维度为[n_Y,None]，dtype = \"float\"\n",
    "\n",
    "    提示：\n",
    "        使用None，因为它让我们可以灵活处理占位符提供的样本数量。事实上，测试/训练期间的样本数量是不同的。\n",
    "\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name=\"Y\")\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_4:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  初始化参数\n",
    "- 初始化tensorflow中的参数，我们将使用Xavier初始化权重和用零来初始化偏差，比如\n",
    "```python\n",
    "W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "``\n",
    "- tf.Variable() 每次都在创建新对象，对于get_variable()来说，对于已经创建的变量对象，就把那个对象返回，如果没有创建变量对象的话，就创建一个新的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    初始化神经网络的参数，参数的维度如下：\n",
    "        W1 : [25, 12288]\n",
    "        b1 : [25, 1]\n",
    "        W2 : [12, 25]\n",
    "        b2 : [12, 1]\n",
    "        W3 : [6, 12]\n",
    "        b3 : [6, 1]\n",
    "\n",
    "    返回：\n",
    "        parameters - 包含了W和b的字典\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1) #指定随机种子\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\",[25,12288],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\",[25,1],initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12, 25], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\", [12, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6, 12], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\", [6, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() #用于清除默认图形堆栈并重置全局默认图形。 \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如预期的那样，这些参数只有物理空间，但是还没有被赋值，这是因为没有通过session执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播\n",
    "- `tf.add(...,...)`加法\n",
    "- `tf.matmul(...,...)` 矩阵乘法\n",
    "- `tf.nn.relu(...)`  ReLU函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    \"\"\"\n",
    "    实现一个模型的前向传播，模型结构为LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    参数：\n",
    "        X - 输入数据的占位符，维度为（输入节点数量，样本数量）\n",
    "        parameters - 包含了W和b的参数的字典\n",
    "\n",
    "    返回：\n",
    "        Z3 - 最后一个LINEAR节点的输出\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)        # Z1 = np.dot(W1, X) + b1\n",
    "    #Z1 = tf.matmul(W1,X) + b1             #也可以这样写\n",
    "    A1 = tf.nn.relu(Z1)                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)     # Z3 = np.dot(W3,Z2) + b3\n",
    "\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算成本\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y):\n",
    "    \"\"\"\n",
    "    计算成本\n",
    "\n",
    "    参数：\n",
    "        Z3 - 前向传播的结果\n",
    "        Y - 标签，一个占位符，和Z3的维度相同\n",
    "\n",
    "    返回：\n",
    "        cost - 成本值\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    logits = tf.transpose(Z3) #转置\n",
    "    labels = tf.transpose(Y)  #转置\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反向传播&更新参数\n",
    "得益于编程框架，所有反向传播和参数更新都在1行代码中处理。计算成本函数后，将创建一个“optimizer”对象。 运行tf.session时，必须将此对象与成本函数一起调用，当被调用时，它将使用所选择的方法和学习速率对给定成本进行优化。\n",
    "\n",
    "举个例子，对于梯度下降：\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "```\n",
    "\n",
    "要进行优化，应该这样做:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```\n",
    "编写代码时，我们经常使用 _ 作为一次性变量来存储我们稍后不需要使用的值。 这里，_具有我们不需要的优化器的评估值（并且c取值为成本变量的值）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(X_train,Y_train,X_test,Y_test,\n",
    "        learning_rate=0.0001,num_epochs=1500,minibatch_size=32,\n",
    "        print_cost=True,is_plot=True):\n",
    "    \"\"\"\n",
    "    实现一个三层的TensorFlow神经网络：LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX\n",
    "\n",
    "    参数：\n",
    "        X_train - 训练集，维度为（输入大小（输入节点数量） = 12288, 样本数量 = 1080）\n",
    "        Y_train - 训练集分类数量，维度为（输出大小(输出节点数量) = 6, 样本数量 = 1080）\n",
    "        X_test - 测试集，维度为（输入大小（输入节点数量） = 12288, 样本数量 = 120）\n",
    "        Y_test - 测试集分类数量，维度为（输出大小(输出节点数量) = 6, 样本数量 = 120）\n",
    "        learning_rate - 学习速率\n",
    "        num_epochs - 整个训练集的遍历次数\n",
    "        mini_batch_size - 每个小批量数据集的大小\n",
    "        print_cost - 是否打印成本，每100代打印一次\n",
    "        is_plot - 是否绘制曲线图\n",
    "\n",
    "    返回：\n",
    "        parameters - 学习后的参数\n",
    "\n",
    "    \"\"\"\n",
    "    ops.reset_default_graph()                #能够重新运行模型而不覆盖tf变量\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (n_x , m)  = X_train.shape               #获取输入节点数量和样本数\n",
    "    n_y = Y_train.shape[0]                   #获取输出节点数量\n",
    "    costs = []                               #成本集\n",
    "\n",
    "    #给X和Y创建placeholder\n",
    "    X,Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    #初始化参数\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    #前向传播\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "\n",
    "    #计算成本\n",
    "    cost = compute_cost(Z3,Y)\n",
    "\n",
    "    #反向传播，使用Adam优化\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    #初始化所有的变量\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #开始会话并计算\n",
    "    with tf.Session() as sess:\n",
    "        #初始化\n",
    "        sess.run(init)\n",
    "\n",
    "        #正常训练的循环\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0  #每代的成本\n",
    "            num_minibatches = int(m / minibatch_size)    #minibatch的总数量\n",
    "            seed = seed + 1\n",
    "            minibatches = tf_utils.random_mini_batches(X_train,Y_train,minibatch_size,seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                #选择一个minibatch\n",
    "                (minibatch_X,minibatch_Y) = minibatch\n",
    "\n",
    "                #数据已经准备好了，开始运行session\n",
    "                _ , minibatch_cost = sess.run([optimizer,cost],feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "\n",
    "                #计算这个minibatch在这一代中所占的误差\n",
    "                epoch_cost = epoch_cost + minibatch_cost / num_minibatches\n",
    "\n",
    "            #记录并打印成本\n",
    "            ## 记录成本\n",
    "            if epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                #是否打印：\n",
    "                if print_cost and epoch % 100 == 0:\n",
    "                        print(\"epoch = \" + str(epoch) + \"    epoch_cost = \" + str(epoch_cost))\n",
    "\n",
    "        #是否绘制图谱\n",
    "        if is_plot:\n",
    "            plt.plot(np.squeeze(costs))\n",
    "            plt.ylabel('cost')\n",
    "            plt.xlabel('iterations (per tens)')\n",
    "            plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "            plt.show()\n",
    "\n",
    "        #保存学习后的参数\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"参数已经保存到session。\")\n",
    "\n",
    "        #计算当前的预测结果\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3),tf.argmax(Y))\n",
    "\n",
    "        #计算准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "        print(\"训练集的准确率：\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"测试集的准确率:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-fa19d65a87cf>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0    epoch_cost = 1.8557019342075693\n",
      "epoch = 100    epoch_cost = 1.0172552358020432\n",
      "epoch = 200    epoch_cost = 0.7331836837710759\n",
      "epoch = 300    epoch_cost = 0.5730706019835038\n",
      "epoch = 400    epoch_cost = 0.46857342620690673\n",
      "epoch = 500    epoch_cost = 0.38122750863884436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-170cdb337fbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#开始训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#结束时间\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-cd20daaf0ffd>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost, is_plot)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;31m#数据已经准备好了，开始运行session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mminibatch_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;31m#计算这个minibatch在这一代中所占的误差\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#开始时间\n",
    "start_time = time.clock()\n",
    "#开始训练\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "#结束时间\n",
    "end_time = time.clock()\n",
    "#计算时差\n",
    "print(\"CPU的执行时间 = \" + str(end_time - start_time) + \" 秒\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "\n",
    "#这是博主自己拍的图片\n",
    "my_image1 = \"5.png\"                                            #定义图片名称\n",
    "fileName1 =\"datasets/fingers/\" + my_image1                      #图片地址\n",
    "image1 = mpimg.imread(fileName1)                               #读取图片\n",
    "plt.imshow(image1)                                             #显示图片\n",
    "my_image1 = image1.reshape(1,64 * 64 * 3).T                    #重构图片\n",
    "my_image_prediction = tf_utils.predict(my_image1, parameters)  #开始预测\n",
    "print(\"预测结果: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=12288, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "1080/1080 [==============================] - 1s 1ms/step - loss: 1.9700 - acc: 0.1657\n",
      "Epoch 2/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 1.7641 - acc: 0.2120\n",
      "Epoch 3/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 1.7177 - acc: 0.2352\n",
      "Epoch 4/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 1.7531 - acc: 0.2148\n",
      "Epoch 5/1500\n",
      "1080/1080 [==============================] - 1s 724us/step - loss: 1.7408 - acc: 0.2380\n",
      "Epoch 6/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 1.7485 - acc: 0.2231\n",
      "Epoch 7/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 1.7343 - acc: 0.2380\n",
      "Epoch 8/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 1.7112 - acc: 0.2472\n",
      "Epoch 9/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 1.6708 - acc: 0.2750\n",
      "Epoch 10/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 1.7199 - acc: 0.2315\n",
      "Epoch 11/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 1.6381 - acc: 0.3565\n",
      "Epoch 12/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 1.6663 - acc: 0.2944\n",
      "Epoch 13/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 1.6053 - acc: 0.3361\n",
      "Epoch 14/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 1.5888 - acc: 0.3611\n",
      "Epoch 15/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 1.5616 - acc: 0.3676\n",
      "Epoch 16/1500\n",
      "1080/1080 [==============================] - 1s 709us/step - loss: 1.5267 - acc: 0.3759\n",
      "Epoch 17/1500\n",
      "1080/1080 [==============================] - 1s 729us/step - loss: 1.5041 - acc: 0.3935\n",
      "Epoch 18/1500\n",
      "1080/1080 [==============================] - 1s 758us/step - loss: 1.4670 - acc: 0.4306\n",
      "Epoch 19/1500\n",
      "1080/1080 [==============================] - 1s 685us/step - loss: 1.4257 - acc: 0.4306\n",
      "Epoch 20/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 1.4078 - acc: 0.4361\n",
      "Epoch 21/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 1.3776 - acc: 0.4565\n",
      "Epoch 22/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 1.3526 - acc: 0.4630\n",
      "Epoch 23/1500\n",
      "1080/1080 [==============================] - 1s 683us/step - loss: 1.3565 - acc: 0.4509 0s - loss: 1.3511 - \n",
      "Epoch 24/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 1.3222 - acc: 0.4685\n",
      "Epoch 25/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 1.2871 - acc: 0.4796\n",
      "Epoch 26/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 1.3222 - acc: 0.4426\n",
      "Epoch 27/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 1.2999 - acc: 0.4565\n",
      "Epoch 28/1500\n",
      "1080/1080 [==============================] - 1s 719us/step - loss: 1.2369 - acc: 0.4991\n",
      "Epoch 29/1500\n",
      "1080/1080 [==============================] - 1s 718us/step - loss: 1.2083 - acc: 0.5028\n",
      "Epoch 30/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 1.2080 - acc: 0.5000\n",
      "Epoch 31/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 1.2855 - acc: 0.4676\n",
      "Epoch 32/1500\n",
      "1080/1080 [==============================] - 1s 742us/step - loss: 1.1653 - acc: 0.5241\n",
      "Epoch 33/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 1.1606 - acc: 0.5176\n",
      "Epoch 34/1500\n",
      "1080/1080 [==============================] - 1s 696us/step - loss: 1.1869 - acc: 0.5074\n",
      "Epoch 35/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 1.1353 - acc: 0.5167\n",
      "Epoch 36/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 1.1229 - acc: 0.5194\n",
      "Epoch 37/1500\n",
      "1080/1080 [==============================] - 1s 706us/step - loss: 1.1510 - acc: 0.5102\n",
      "Epoch 38/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 1.1925 - acc: 0.4843\n",
      "Epoch 39/1500\n",
      "1080/1080 [==============================] - 1s 734us/step - loss: 1.0692 - acc: 0.5657\n",
      "Epoch 40/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 1.0580 - acc: 0.5759\n",
      "Epoch 41/1500\n",
      "1080/1080 [==============================] - 1s 749us/step - loss: 1.0977 - acc: 0.5546\n",
      "Epoch 42/1500\n",
      "1080/1080 [==============================] - 1s 754us/step - loss: 1.0614 - acc: 0.5556\n",
      "Epoch 43/1500\n",
      "1080/1080 [==============================] - 1s 735us/step - loss: 1.0357 - acc: 0.5657\n",
      "Epoch 44/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 1.0487 - acc: 0.5648\n",
      "Epoch 45/1500\n",
      "1080/1080 [==============================] - 1s 738us/step - loss: 1.0665 - acc: 0.5546\n",
      "Epoch 46/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 1.0103 - acc: 0.5870\n",
      "Epoch 47/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 1.0576 - acc: 0.5444\n",
      "Epoch 48/1500\n",
      "1080/1080 [==============================] - 1s 710us/step - loss: 1.0153 - acc: 0.5694\n",
      "Epoch 49/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.9891 - acc: 0.5926\n",
      "Epoch 50/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 1.0079 - acc: 0.5926\n",
      "Epoch 51/1500\n",
      "1080/1080 [==============================] - 1s 765us/step - loss: 0.9539 - acc: 0.6009\n",
      "Epoch 52/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.9777 - acc: 0.5750\n",
      "Epoch 53/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 1.0473 - acc: 0.5667\n",
      "Epoch 54/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.9673 - acc: 0.6222\n",
      "Epoch 55/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.9745 - acc: 0.5870\n",
      "Epoch 56/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.9808 - acc: 0.5889\n",
      "Epoch 57/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.9061 - acc: 0.6241\n",
      "Epoch 58/1500\n",
      "1080/1080 [==============================] - 1s 709us/step - loss: 0.9292 - acc: 0.6148\n",
      "Epoch 59/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 1.0105 - acc: 0.5491\n",
      "Epoch 60/1500\n",
      "1080/1080 [==============================] - 1s 709us/step - loss: 0.9478 - acc: 0.6019\n",
      "Epoch 61/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.9939 - acc: 0.5787\n",
      "Epoch 62/1500\n",
      "1080/1080 [==============================] - 1s 750us/step - loss: 0.8923 - acc: 0.6361\n",
      "Epoch 63/1500\n",
      "1080/1080 [==============================] - 1s 724us/step - loss: 1.0804 - acc: 0.5250\n",
      "Epoch 64/1500\n",
      "1080/1080 [==============================] - 1s 830us/step - loss: 0.9831 - acc: 0.5676\n",
      "Epoch 65/1500\n",
      "1080/1080 [==============================] - 1s 775us/step - loss: 0.8874 - acc: 0.6250\n",
      "Epoch 66/1500\n",
      "1080/1080 [==============================] - 1s 755us/step - loss: 0.9182 - acc: 0.6185\n",
      "Epoch 67/1500\n",
      "1080/1080 [==============================] - 1s 739us/step - loss: 0.8890 - acc: 0.6333\n",
      "Epoch 68/1500\n",
      "1080/1080 [==============================] - 1s 755us/step - loss: 0.8957 - acc: 0.6157\n",
      "Epoch 69/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.9136 - acc: 0.6287\n",
      "Epoch 70/1500\n",
      "1080/1080 [==============================] - 1s 762us/step - loss: 0.9871 - acc: 0.5787\n",
      "Epoch 71/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.9002 - acc: 0.6231\n",
      "Epoch 72/1500\n",
      "1080/1080 [==============================] - 1s 729us/step - loss: 0.9241 - acc: 0.6148\n",
      "Epoch 73/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.8854 - acc: 0.6389\n",
      "Epoch 74/1500\n",
      "1080/1080 [==============================] - 1s 743us/step - loss: 0.8574 - acc: 0.6398\n",
      "Epoch 75/1500\n",
      "1080/1080 [==============================] - 1s 817us/step - loss: 0.9383 - acc: 0.6130\n",
      "Epoch 76/1500\n",
      "1080/1080 [==============================] - 1s 749us/step - loss: 0.9270 - acc: 0.6093\n",
      "Epoch 77/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 1.0441 - acc: 0.5481\n",
      "Epoch 78/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.8589 - acc: 0.6491\n",
      "Epoch 79/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.8326 - acc: 0.6620\n",
      "Epoch 80/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.8127 - acc: 0.6620\n",
      "Epoch 81/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.8706 - acc: 0.6250\n",
      "Epoch 82/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.8227 - acc: 0.6667\n",
      "Epoch 83/1500\n",
      "1080/1080 [==============================] - 1s 604us/step - loss: 1.0371 - acc: 0.5398\n",
      "Epoch 84/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.8090 - acc: 0.6583\n",
      "Epoch 85/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.8406 - acc: 0.6398 0s - loss: 0.8229 - acc: 0.64\n",
      "Epoch 86/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.8127 - acc: 0.6657\n",
      "Epoch 87/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.7740 - acc: 0.6870\n",
      "Epoch 88/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.7817 - acc: 0.6741\n",
      "Epoch 89/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.7631 - acc: 0.6898\n",
      "Epoch 90/1500\n",
      "1080/1080 [==============================] - 1s 723us/step - loss: 0.7766 - acc: 0.6806\n",
      "Epoch 91/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.7908 - acc: 0.6593\n",
      "Epoch 92/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.7656 - acc: 0.6935\n",
      "Epoch 93/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.8051 - acc: 0.6593 0s - loss: 0.7962 - acc: 0.66\n",
      "Epoch 94/1500\n",
      "1080/1080 [==============================] - 1s 797us/step - loss: 0.7427 - acc: 0.7009 0s - loss: 0.6157 - ac - ETA: 0s - loss: 0.7550 - acc: 0.6\n",
      "Epoch 95/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.7920 - acc: 0.6944\n",
      "Epoch 96/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.9175 - acc: 0.6167\n",
      "Epoch 97/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 0.7408 - acc: 0.6944\n",
      "Epoch 98/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.7611 - acc: 0.6907 0s - loss: 0.8220 - acc:\n",
      "Epoch 99/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.7581 - acc: 0.6935\n",
      "Epoch 100/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.8851 - acc: 0.6065\n",
      "Epoch 101/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.8048 - acc: 0.6565\n",
      "Epoch 102/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.7398 - acc: 0.6917\n",
      "Epoch 103/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.7168 - acc: 0.7130\n",
      "Epoch 104/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.7569 - acc: 0.6944\n",
      "Epoch 105/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.7014 - acc: 0.7241\n",
      "Epoch 106/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.6888 - acc: 0.7148\n",
      "Epoch 107/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.6949 - acc: 0.7241\n",
      "Epoch 108/1500\n",
      "1080/1080 [==============================] - 1s 696us/step - loss: 0.7166 - acc: 0.7083\n",
      "Epoch 109/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.6863 - acc: 0.7296\n",
      "Epoch 110/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.8322 - acc: 0.6491\n",
      "Epoch 111/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.7619 - acc: 0.6824\n",
      "Epoch 112/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.7485 - acc: 0.6898\n",
      "Epoch 113/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.6599 - acc: 0.7352\n",
      "Epoch 114/1500\n",
      "1080/1080 [==============================] - 1s 736us/step - loss: 0.8034 - acc: 0.6500\n",
      "Epoch 115/1500\n",
      "1080/1080 [==============================] - 1s 728us/step - loss: 0.6877 - acc: 0.7204\n",
      "Epoch 116/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.7078 - acc: 0.7019 0s - loss: 0.7006 - acc: 0.\n",
      "Epoch 117/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.6990 - acc: 0.7204\n",
      "Epoch 118/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.8200 - acc: 0.6519\n",
      "Epoch 119/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.7111 - acc: 0.7065\n",
      "Epoch 120/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.7351 - acc: 0.7019\n",
      "Epoch 121/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.6871 - acc: 0.7287\n",
      "Epoch 122/1500\n",
      "1080/1080 [==============================] - 1s 710us/step - loss: 0.6758 - acc: 0.7315\n",
      "Epoch 123/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.6741 - acc: 0.7250\n",
      "Epoch 124/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.7869 - acc: 0.6731\n",
      "Epoch 125/1500\n",
      "1080/1080 [==============================] - 1s 716us/step - loss: 0.7797 - acc: 0.6602\n",
      "Epoch 126/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.7189 - acc: 0.7037\n",
      "Epoch 127/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.6533 - acc: 0.7417\n",
      "Epoch 128/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.6238 - acc: 0.7519\n",
      "Epoch 129/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.6677 - acc: 0.7380\n",
      "Epoch 130/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.8929 - acc: 0.6231\n",
      "Epoch 131/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.8228 - acc: 0.6583 0s - loss: 0.8548 - acc: 0.6\n",
      "Epoch 132/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.7560 - acc: 0.6685\n",
      "Epoch 133/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.6798 - acc: 0.7120\n",
      "Epoch 134/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.6797 - acc: 0.7185\n",
      "Epoch 135/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.6847 - acc: 0.6981\n",
      "Epoch 136/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.6403 - acc: 0.7463\n",
      "Epoch 137/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.5993 - acc: 0.7796\n",
      "Epoch 138/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.6058 - acc: 0.7704\n",
      "Epoch 139/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.5927 - acc: 0.7676\n",
      "Epoch 140/1500\n",
      "1080/1080 [==============================] - 1s 712us/step - loss: 0.6267 - acc: 0.7556\n",
      "Epoch 141/1500\n",
      "1080/1080 [==============================] - 1s 738us/step - loss: 0.6230 - acc: 0.7546\n",
      "Epoch 142/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.6610 - acc: 0.7269\n",
      "Epoch 143/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.6527 - acc: 0.7194\n",
      "Epoch 144/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.6247 - acc: 0.7472\n",
      "Epoch 145/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.6972 - acc: 0.7056\n",
      "Epoch 146/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.6338 - acc: 0.7352\n",
      "Epoch 147/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.6755 - acc: 0.7157\n",
      "Epoch 148/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.6031 - acc: 0.7694\n",
      "Epoch 149/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.6473 - acc: 0.7352\n",
      "Epoch 150/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.6273 - acc: 0.7380\n",
      "Epoch 151/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.8126 - acc: 0.6537\n",
      "Epoch 152/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.6546 - acc: 0.7315\n",
      "Epoch 153/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.6126 - acc: 0.7417\n",
      "Epoch 154/1500\n",
      "1080/1080 [==============================] - 1s 695us/step - loss: 0.6001 - acc: 0.7620\n",
      "Epoch 155/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.5867 - acc: 0.7611\n",
      "Epoch 156/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.5791 - acc: 0.7704\n",
      "Epoch 157/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.5574 - acc: 0.7815\n",
      "Epoch 158/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.6128 - acc: 0.7361\n",
      "Epoch 159/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.6546 - acc: 0.7259\n",
      "Epoch 160/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.6553 - acc: 0.7333\n",
      "Epoch 161/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.5484 - acc: 0.7843 0s - loss: 0.5512 - acc: \n",
      "Epoch 162/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.5380 - acc: 0.7954\n",
      "Epoch 163/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.6440 - acc: 0.7259\n",
      "Epoch 164/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.5664 - acc: 0.7722\n",
      "Epoch 165/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.5637 - acc: 0.7815\n",
      "Epoch 166/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.6736 - acc: 0.7157\n",
      "Epoch 167/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.5712 - acc: 0.7731\n",
      "Epoch 168/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.5661 - acc: 0.7759\n",
      "Epoch 169/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.6277 - acc: 0.7389\n",
      "Epoch 170/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.7295 - acc: 0.6833\n",
      "Epoch 171/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.5728 - acc: 0.7713\n",
      "Epoch 172/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.5953 - acc: 0.7481\n",
      "Epoch 173/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.6297 - acc: 0.7454\n",
      "Epoch 174/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.5538 - acc: 0.7852\n",
      "Epoch 175/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.7014 - acc: 0.6917\n",
      "Epoch 176/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.5611 - acc: 0.7796\n",
      "Epoch 177/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.5526 - acc: 0.7713\n",
      "Epoch 178/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.5304 - acc: 0.8037\n",
      "Epoch 179/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.5545 - acc: 0.7843\n",
      "Epoch 180/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.5318 - acc: 0.7917\n",
      "Epoch 181/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.5371 - acc: 0.7870\n",
      "Epoch 182/1500\n",
      "1080/1080 [==============================] - 1s 600us/step - loss: 0.5393 - acc: 0.7843\n",
      "Epoch 183/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.5189 - acc: 0.8102\n",
      "Epoch 184/1500\n",
      "1080/1080 [==============================] - 1s 603us/step - loss: 0.5544 - acc: 0.7759\n",
      "Epoch 185/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.5937 - acc: 0.7648\n",
      "Epoch 186/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.5285 - acc: 0.7935\n",
      "Epoch 187/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.5093 - acc: 0.8046\n",
      "Epoch 188/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.8728 - acc: 0.6870\n",
      "Epoch 189/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.6273 - acc: 0.7389\n",
      "Epoch 190/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.5056 - acc: 0.8111\n",
      "Epoch 191/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.5189 - acc: 0.8083\n",
      "Epoch 192/1500\n",
      "1080/1080 [==============================] - 1s 728us/step - loss: 0.5631 - acc: 0.7759\n",
      "Epoch 193/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.4927 - acc: 0.8037\n",
      "Epoch 194/1500\n",
      "1080/1080 [==============================] - 1s 729us/step - loss: 0.6891 - acc: 0.6889 0s - loss: 0.6622 - acc: 0.7\n",
      "Epoch 195/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.6999 - acc: 0.6963\n",
      "Epoch 196/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.5541 - acc: 0.7759\n",
      "Epoch 197/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.5895 - acc: 0.7509\n",
      "Epoch 198/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.5820 - acc: 0.7463\n",
      "Epoch 199/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.5919 - acc: 0.7380\n",
      "Epoch 200/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.4848 - acc: 0.8139\n",
      "Epoch 201/1500\n",
      "1080/1080 [==============================] - 1s 745us/step - loss: 0.4840 - acc: 0.8185\n",
      "Epoch 202/1500\n",
      "1080/1080 [==============================] - 1s 750us/step - loss: 0.5001 - acc: 0.8102\n",
      "Epoch 203/1500\n",
      "1080/1080 [==============================] - 1s 758us/step - loss: 0.4697 - acc: 0.8194\n",
      "Epoch 204/1500\n",
      "1080/1080 [==============================] - 1s 738us/step - loss: 0.6409 - acc: 0.7130\n",
      "Epoch 205/1500\n",
      "1080/1080 [==============================] - 1s 736us/step - loss: 0.5263 - acc: 0.7824\n",
      "Epoch 206/1500\n",
      "1080/1080 [==============================] - 1s 711us/step - loss: 0.4837 - acc: 0.8111\n",
      "Epoch 207/1500\n",
      "1080/1080 [==============================] - 1s 729us/step - loss: 0.5094 - acc: 0.8037\n",
      "Epoch 208/1500\n",
      "1080/1080 [==============================] - 1s 755us/step - loss: 0.5076 - acc: 0.8037\n",
      "Epoch 209/1500\n",
      "1080/1080 [==============================] - 1s 736us/step - loss: 0.5006 - acc: 0.7972\n",
      "Epoch 210/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.5411 - acc: 0.7759\n",
      "Epoch 211/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.6410 - acc: 0.7306\n",
      "Epoch 212/1500\n",
      "1080/1080 [==============================] - 1s 769us/step - loss: 0.5093 - acc: 0.7861\n",
      "Epoch 213/1500\n",
      "1080/1080 [==============================] - 1s 736us/step - loss: 0.4808 - acc: 0.8167\n",
      "Epoch 214/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.5569 - acc: 0.7731\n",
      "Epoch 215/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.5447 - acc: 0.7657\n",
      "Epoch 216/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.5555 - acc: 0.7750\n",
      "Epoch 217/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.4661 - acc: 0.8315\n",
      "Epoch 218/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.4589 - acc: 0.8352\n",
      "Epoch 219/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.4570 - acc: 0.8259\n",
      "Epoch 220/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.4760 - acc: 0.8185 0s - loss: 0.4598 - acc\n",
      "Epoch 221/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.4762 - acc: 0.8093\n",
      "Epoch 222/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.7786 - acc: 0.7065\n",
      "Epoch 223/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.6227 - acc: 0.7463\n",
      "Epoch 224/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.4474 - acc: 0.8333\n",
      "Epoch 225/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.4602 - acc: 0.8269\n",
      "Epoch 226/1500\n",
      "1080/1080 [==============================] - 1s 750us/step - loss: 0.4461 - acc: 0.8306\n",
      "Epoch 227/1500\n",
      "1080/1080 [==============================] - 1s 815us/step - loss: 0.4408 - acc: 0.8380\n",
      "Epoch 228/1500\n",
      "1080/1080 [==============================] - 1s 752us/step - loss: 0.5105 - acc: 0.7917\n",
      "Epoch 229/1500\n",
      "1080/1080 [==============================] - 1s 737us/step - loss: 0.4533 - acc: 0.8269\n",
      "Epoch 230/1500\n",
      "1080/1080 [==============================] - 1s 711us/step - loss: 0.4728 - acc: 0.8194\n",
      "Epoch 231/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.4263 - acc: 0.8509\n",
      "Epoch 232/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.5248 - acc: 0.7944\n",
      "Epoch 233/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.6286 - acc: 0.7463\n",
      "Epoch 234/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.4597 - acc: 0.8157\n",
      "Epoch 235/1500\n",
      "1080/1080 [==============================] - 1s 732us/step - loss: 0.4347 - acc: 0.8407\n",
      "Epoch 236/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.4930 - acc: 0.8009\n",
      "Epoch 237/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.5759 - acc: 0.7639\n",
      "Epoch 238/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.5787 - acc: 0.7556\n",
      "Epoch 239/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.4666 - acc: 0.8167\n",
      "Epoch 240/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.4215 - acc: 0.8398\n",
      "Epoch 241/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.5016 - acc: 0.7898\n",
      "Epoch 242/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.4996 - acc: 0.7935\n",
      "Epoch 243/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.4389 - acc: 0.8306\n",
      "Epoch 244/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.4482 - acc: 0.8241\n",
      "Epoch 245/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.4940 - acc: 0.8009 0s - loss: 0.5041 - \n",
      "Epoch 246/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.4298 - acc: 0.8361\n",
      "Epoch 247/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.4854 - acc: 0.8139\n",
      "Epoch 248/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.4725 - acc: 0.8065\n",
      "Epoch 249/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.4516 - acc: 0.8213\n",
      "Epoch 250/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.4496 - acc: 0.8259\n",
      "Epoch 251/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.6088 - acc: 0.7426\n",
      "Epoch 252/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.4455 - acc: 0.8222\n",
      "Epoch 253/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.4193 - acc: 0.8380\n",
      "Epoch 254/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.4213 - acc: 0.8417\n",
      "Epoch 255/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.5539 - acc: 0.7481\n",
      "Epoch 256/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.4611 - acc: 0.8139\n",
      "Epoch 257/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.6112 - acc: 0.7454\n",
      "Epoch 258/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.5041 - acc: 0.7926\n",
      "Epoch 259/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.4169 - acc: 0.8444\n",
      "Epoch 260/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.4357 - acc: 0.8472\n",
      "Epoch 261/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.4182 - acc: 0.8389\n",
      "Epoch 262/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.5928 - acc: 0.7454\n",
      "Epoch 263/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.4125 - acc: 0.8454\n",
      "Epoch 264/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.4140 - acc: 0.8491\n",
      "Epoch 265/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.4241 - acc: 0.8426\n",
      "Epoch 266/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.3876 - acc: 0.8528\n",
      "Epoch 267/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.4513 - acc: 0.8185\n",
      "Epoch 268/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.4919 - acc: 0.7898\n",
      "Epoch 269/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 0.3963 - acc: 0.8417 0s - loss: 0.3708 - acc:\n",
      "Epoch 270/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.3967 - acc: 0.8583\n",
      "Epoch 271/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.3883 - acc: 0.8546\n",
      "Epoch 272/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.4443 - acc: 0.8241\n",
      "Epoch 273/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.4389 - acc: 0.8333\n",
      "Epoch 274/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.4290 - acc: 0.8389\n",
      "Epoch 275/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.4467 - acc: 0.8250\n",
      "Epoch 276/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.7310 - acc: 0.7130\n",
      "Epoch 277/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.4388 - acc: 0.8287\n",
      "Epoch 278/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.3899 - acc: 0.8537\n",
      "Epoch 279/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.3813 - acc: 0.8500\n",
      "Epoch 280/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.4485 - acc: 0.8241 0s - loss: 0.3994 - acc:\n",
      "Epoch 281/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.4209 - acc: 0.8352\n",
      "Epoch 282/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.4652 - acc: 0.8185\n",
      "Epoch 283/1500\n",
      "1080/1080 [==============================] - 1s 725us/step - loss: 0.4074 - acc: 0.8444\n",
      "Epoch 284/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.4222 - acc: 0.8370\n",
      "Epoch 285/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.3802 - acc: 0.8583\n",
      "Epoch 286/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.3997 - acc: 0.8491\n",
      "Epoch 287/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.3880 - acc: 0.8472\n",
      "Epoch 288/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.4686 - acc: 0.8102\n",
      "Epoch 289/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.5302 - acc: 0.7759\n",
      "Epoch 290/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.3769 - acc: 0.8583\n",
      "Epoch 291/1500\n",
      "1080/1080 [==============================] - 1s 696us/step - loss: 0.3989 - acc: 0.8500\n",
      "Epoch 292/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.3922 - acc: 0.8556\n",
      "Epoch 293/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.3498 - acc: 0.8694\n",
      "Epoch 294/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.3622 - acc: 0.8620\n",
      "Epoch 295/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.3931 - acc: 0.8491\n",
      "Epoch 296/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.4080 - acc: 0.8380\n",
      "Epoch 297/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.5539 - acc: 0.7889\n",
      "Epoch 298/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.6094 - acc: 0.7713\n",
      "Epoch 299/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.3695 - acc: 0.8630\n",
      "Epoch 300/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.5244 - acc: 0.7769\n",
      "Epoch 301/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.7157 - acc: 0.7157\n",
      "Epoch 302/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.4848 - acc: 0.7991\n",
      "Epoch 303/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.4134 - acc: 0.8361\n",
      "Epoch 304/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.3589 - acc: 0.8731\n",
      "Epoch 305/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.5448 - acc: 0.7657\n",
      "Epoch 306/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.5019 - acc: 0.7972\n",
      "Epoch 307/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.6403 - acc: 0.7278\n",
      "Epoch 308/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.4067 - acc: 0.8407\n",
      "Epoch 309/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.3750 - acc: 0.8565\n",
      "Epoch 310/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.3792 - acc: 0.8556\n",
      "Epoch 311/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.5579 - acc: 0.7574\n",
      "Epoch 312/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.7969 - acc: 0.6852\n",
      "Epoch 313/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.5218 - acc: 0.7926\n",
      "Epoch 314/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.3678 - acc: 0.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.7111 - acc: 0.7046\n",
      "Epoch 316/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.5725 - acc: 0.7500\n",
      "Epoch 317/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.4688 - acc: 0.7991\n",
      "Epoch 318/1500\n",
      "1080/1080 [==============================] - 1s 589us/step - loss: 0.3740 - acc: 0.8565\n",
      "Epoch 319/1500\n",
      "1080/1080 [==============================] - 1s 601us/step - loss: 0.4797 - acc: 0.7963\n",
      "Epoch 320/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.3711 - acc: 0.8602\n",
      "Epoch 321/1500\n",
      "1080/1080 [==============================] - 1s 600us/step - loss: 0.3904 - acc: 0.8407\n",
      "Epoch 322/1500\n",
      "1080/1080 [==============================] - 1s 601us/step - loss: 0.4491 - acc: 0.8093\n",
      "Epoch 323/1500\n",
      "1080/1080 [==============================] - 1s 599us/step - loss: 0.3967 - acc: 0.8491\n",
      "Epoch 324/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.3454 - acc: 0.8806\n",
      "Epoch 325/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.3341 - acc: 0.8917\n",
      "Epoch 326/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.3616 - acc: 0.8704\n",
      "Epoch 327/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.3492 - acc: 0.8685\n",
      "Epoch 328/1500\n",
      "1080/1080 [==============================] - 1s 601us/step - loss: 0.3549 - acc: 0.8648\n",
      "Epoch 329/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.4420 - acc: 0.8204\n",
      "Epoch 330/1500\n",
      "1080/1080 [==============================] - 1s 601us/step - loss: 0.3418 - acc: 0.8815\n",
      "Epoch 331/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.3485 - acc: 0.8759\n",
      "Epoch 332/1500\n",
      "1080/1080 [==============================] - 1s 603us/step - loss: 0.3411 - acc: 0.8778\n",
      "Epoch 333/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.4015 - acc: 0.8398\n",
      "Epoch 334/1500\n",
      "1080/1080 [==============================] - 1s 597us/step - loss: 0.4275 - acc: 0.8250\n",
      "Epoch 335/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.4136 - acc: 0.8287\n",
      "Epoch 336/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.3330 - acc: 0.8731\n",
      "Epoch 337/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.3887 - acc: 0.8500\n",
      "Epoch 338/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.3658 - acc: 0.8574\n",
      "Epoch 339/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.3692 - acc: 0.8620\n",
      "Epoch 340/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.7819 - acc: 0.7028\n",
      "Epoch 341/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.3570 - acc: 0.8611\n",
      "Epoch 342/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.4265 - acc: 0.8185\n",
      "Epoch 343/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.3591 - acc: 0.8574\n",
      "Epoch 344/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.3448 - acc: 0.8630\n",
      "Epoch 345/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.3633 - acc: 0.8509\n",
      "Epoch 346/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.5698 - acc: 0.7704\n",
      "Epoch 347/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.6547 - acc: 0.7454\n",
      "Epoch 348/1500\n",
      "1080/1080 [==============================] - ETA: 0s - loss: 0.3253 - acc: 0.888 - 1s 608us/step - loss: 0.3235 - acc: 0.8861\n",
      "Epoch 349/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.3232 - acc: 0.8843\n",
      "Epoch 350/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.3785 - acc: 0.8611\n",
      "Epoch 351/1500\n",
      "1080/1080 [==============================] - 1s 795us/step - loss: 0.3565 - acc: 0.8556\n",
      "Epoch 352/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.4490 - acc: 0.8148\n",
      "Epoch 353/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.3946 - acc: 0.8417\n",
      "Epoch 354/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.4063 - acc: 0.8389\n",
      "Epoch 355/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.3057 - acc: 0.8898\n",
      "Epoch 356/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.3070 - acc: 0.8917 0s - loss: 0.3044 - acc: 0.89\n",
      "Epoch 357/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.3234 - acc: 0.8833\n",
      "Epoch 358/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.3049 - acc: 0.8954\n",
      "Epoch 359/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.3456 - acc: 0.8602\n",
      "Epoch 360/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.3398 - acc: 0.8713\n",
      "Epoch 361/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.4297 - acc: 0.8269\n",
      "Epoch 362/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.6442 - acc: 0.7454 0s - loss: 0.6520 - acc: 0.742\n",
      "Epoch 363/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.3148 - acc: 0.8852\n",
      "Epoch 364/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.3641 - acc: 0.8574\n",
      "Epoch 365/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.3949 - acc: 0.8324\n",
      "Epoch 366/1500\n",
      "1080/1080 [==============================] - 1s 724us/step - loss: 0.3262 - acc: 0.8861\n",
      "Epoch 367/1500\n",
      "1080/1080 [==============================] - 1s 719us/step - loss: 0.3532 - acc: 0.8556\n",
      "Epoch 368/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.2968 - acc: 0.8926\n",
      "Epoch 369/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.3174 - acc: 0.8759\n",
      "Epoch 370/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.3797 - acc: 0.8426\n",
      "Epoch 371/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.7423 - acc: 0.7287\n",
      "Epoch 372/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.3246 - acc: 0.8806\n",
      "Epoch 373/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.3078 - acc: 0.8852\n",
      "Epoch 374/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.3455 - acc: 0.8694\n",
      "Epoch 375/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.3238 - acc: 0.8713\n",
      "Epoch 376/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.4453 - acc: 0.8213\n",
      "Epoch 377/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.4303 - acc: 0.8176\n",
      "Epoch 378/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.3494 - acc: 0.8685\n",
      "Epoch 379/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.3477 - acc: 0.8685\n",
      "Epoch 380/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.2934 - acc: 0.8889\n",
      "Epoch 381/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.3480 - acc: 0.8593\n",
      "Epoch 382/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.6187 - acc: 0.7444\n",
      "Epoch 383/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.6283 - acc: 0.7370\n",
      "Epoch 384/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.3287 - acc: 0.8778\n",
      "Epoch 385/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.3788 - acc: 0.8481\n",
      "Epoch 386/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.3135 - acc: 0.8815\n",
      "Epoch 387/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.3176 - acc: 0.8759\n",
      "Epoch 388/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.3708 - acc: 0.8463\n",
      "Epoch 389/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.2988 - acc: 0.8954\n",
      "Epoch 390/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.3024 - acc: 0.8898\n",
      "Epoch 391/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.2916 - acc: 0.8972\n",
      "Epoch 392/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.3739 - acc: 0.8481\n",
      "Epoch 393/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.2887 - acc: 0.8972\n",
      "Epoch 394/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.3374 - acc: 0.8639\n",
      "Epoch 395/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.2903 - acc: 0.9000\n",
      "Epoch 396/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.4071 - acc: 0.8454\n",
      "Epoch 397/1500\n",
      "1080/1080 [==============================] - 1s 601us/step - loss: 0.5342 - acc: 0.7861\n",
      "Epoch 398/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.3130 - acc: 0.8750\n",
      "Epoch 399/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.3227 - acc: 0.8750\n",
      "Epoch 400/1500\n",
      "1080/1080 [==============================] - 1s 599us/step - loss: 0.3294 - acc: 0.8676\n",
      "Epoch 401/1500\n",
      "1080/1080 [==============================] - 1s 599us/step - loss: 0.2872 - acc: 0.8954\n",
      "Epoch 402/1500\n",
      "1080/1080 [==============================] - 1s 550us/step - loss: 0.2811 - acc: 0.8963\n",
      "Epoch 403/1500\n",
      "1080/1080 [==============================] - 1s 564us/step - loss: 0.3384 - acc: 0.8704\n",
      "Epoch 404/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.3083 - acc: 0.8870\n",
      "Epoch 405/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.2651 - acc: 0.9056\n",
      "Epoch 406/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.2992 - acc: 0.8861\n",
      "Epoch 407/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.2896 - acc: 0.8852\n",
      "Epoch 408/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.6359 - acc: 0.7667\n",
      "Epoch 409/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.3817 - acc: 0.8370\n",
      "Epoch 410/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.3412 - acc: 0.8602\n",
      "Epoch 411/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.3120 - acc: 0.8769\n",
      "Epoch 412/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.4306 - acc: 0.8231\n",
      "Epoch 413/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.2940 - acc: 0.8944\n",
      "Epoch 414/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.2642 - acc: 0.9000\n",
      "Epoch 415/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.3227 - acc: 0.8750\n",
      "Epoch 416/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.3144 - acc: 0.8833\n",
      "Epoch 417/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.3064 - acc: 0.8852\n",
      "Epoch 418/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.2762 - acc: 0.8935\n",
      "Epoch 419/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.3342 - acc: 0.8694\n",
      "Epoch 420/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.2952 - acc: 0.8954\n",
      "Epoch 421/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.2602 - acc: 0.9074\n",
      "Epoch 422/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.3699 - acc: 0.8454\n",
      "Epoch 423/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.2923 - acc: 0.8861\n",
      "Epoch 424/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.4054 - acc: 0.8250\n",
      "Epoch 425/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.2978 - acc: 0.8861\n",
      "Epoch 426/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.2766 - acc: 0.8981\n",
      "Epoch 427/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.3792 - acc: 0.8500\n",
      "Epoch 428/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.3236 - acc: 0.8704\n",
      "Epoch 429/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.3716 - acc: 0.8509 0s - loss: 0.3788 - acc: 0.84\n",
      "Epoch 430/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.3050 - acc: 0.8815\n",
      "Epoch 431/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.2788 - acc: 0.8926\n",
      "Epoch 432/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.3820 - acc: 0.8343\n",
      "Epoch 433/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.2865 - acc: 0.8907\n",
      "Epoch 434/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.2707 - acc: 0.9000\n",
      "Epoch 435/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.3228 - acc: 0.8741\n",
      "Epoch 436/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.2516 - acc: 0.9120\n",
      "Epoch 437/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.2724 - acc: 0.8954\n",
      "Epoch 438/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.3138 - acc: 0.8741\n",
      "Epoch 439/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.3269 - acc: 0.8694 0s - loss: 0.2963 - acc: 0\n",
      "Epoch 440/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.5499 - acc: 0.7806\n",
      "Epoch 441/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.5628 - acc: 0.7843\n",
      "Epoch 442/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.3794 - acc: 0.8491\n",
      "Epoch 443/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.3946 - acc: 0.8435\n",
      "Epoch 444/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.2444 - acc: 0.9139\n",
      "Epoch 445/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.2490 - acc: 0.9037\n",
      "Epoch 446/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.2445 - acc: 0.9148\n",
      "Epoch 447/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.2517 - acc: 0.9111\n",
      "Epoch 448/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.4623 - acc: 0.8056\n",
      "Epoch 449/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.3053 - acc: 0.8787\n",
      "Epoch 450/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.2600 - acc: 0.9000\n",
      "Epoch 451/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.2584 - acc: 0.8981\n",
      "Epoch 452/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.2723 - acc: 0.9019\n",
      "Epoch 453/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.2963 - acc: 0.8815\n",
      "Epoch 454/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.3156 - acc: 0.8704\n",
      "Epoch 455/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.2914 - acc: 0.8889\n",
      "Epoch 456/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.2522 - acc: 0.9056\n",
      "Epoch 457/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.2969 - acc: 0.8898\n",
      "Epoch 458/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.3384 - acc: 0.8685\n",
      "Epoch 459/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.3428 - acc: 0.8667\n",
      "Epoch 460/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.2484 - acc: 0.9093\n",
      "Epoch 461/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.2331 - acc: 0.9111\n",
      "Epoch 462/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.2437 - acc: 0.9176\n",
      "Epoch 463/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.2597 - acc: 0.8963\n",
      "Epoch 464/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.2504 - acc: 0.9083\n",
      "Epoch 465/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.2769 - acc: 0.8926\n",
      "Epoch 466/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.2300 - acc: 0.9148\n",
      "Epoch 467/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.2176 - acc: 0.9204\n",
      "Epoch 468/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.3313 - acc: 0.8630\n",
      "Epoch 469/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.3191 - acc: 0.8694\n",
      "Epoch 470/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.2439 - acc: 0.9093\n",
      "Epoch 471/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.2399 - acc: 0.9083\n",
      "Epoch 472/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.2499 - acc: 0.9093\n",
      "Epoch 473/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.2894 - acc: 0.8880\n",
      "Epoch 474/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.2734 - acc: 0.8935\n",
      "Epoch 475/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.3240 - acc: 0.8731\n",
      "Epoch 476/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.2235 - acc: 0.9157\n",
      "Epoch 477/1500\n",
      "1080/1080 [==============================] - 1s 752us/step - loss: 0.2732 - acc: 0.8963\n",
      "Epoch 478/1500\n",
      "1080/1080 [==============================] - 1s 730us/step - loss: 0.3173 - acc: 0.8796\n",
      "Epoch 479/1500\n",
      "1080/1080 [==============================] - 1s 763us/step - loss: 0.4158 - acc: 0.8389\n",
      "Epoch 480/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.4406 - acc: 0.8185\n",
      "Epoch 481/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.2345 - acc: 0.9148\n",
      "Epoch 482/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.2462 - acc: 0.9102\n",
      "Epoch 483/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.2546 - acc: 0.9037\n",
      "Epoch 484/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.2227 - acc: 0.9148\n",
      "Epoch 485/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.2080 - acc: 0.9241\n",
      "Epoch 486/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 0.2246 - acc: 0.9167\n",
      "Epoch 487/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.2100 - acc: 0.9222\n",
      "Epoch 488/1500\n",
      "1080/1080 [==============================] - 1s 729us/step - loss: 0.2916 - acc: 0.8880\n",
      "Epoch 489/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.7925 - acc: 0.7296\n",
      "Epoch 490/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.2773 - acc: 0.8880\n",
      "Epoch 491/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.2340 - acc: 0.9111\n",
      "Epoch 492/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.3242 - acc: 0.8657\n",
      "Epoch 493/1500\n",
      "1080/1080 [==============================] - 1s 776us/step - loss: 0.2417 - acc: 0.9093\n",
      "Epoch 494/1500\n",
      "1080/1080 [==============================] - 1s 839us/step - loss: 0.2123 - acc: 0.9250\n",
      "Epoch 495/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.2071 - acc: 0.9287\n",
      "Epoch 496/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.2653 - acc: 0.8991\n",
      "Epoch 497/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.2692 - acc: 0.8963\n",
      "Epoch 498/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.2572 - acc: 0.9009\n",
      "Epoch 499/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.4877 - acc: 0.7991\n",
      "Epoch 500/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.3536 - acc: 0.8639\n",
      "Epoch 501/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.2142 - acc: 0.9213\n",
      "Epoch 502/1500\n",
      "1080/1080 [==============================] - 1s 769us/step - loss: 0.2067 - acc: 0.9241\n",
      "Epoch 503/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.2059 - acc: 0.9222 0s - loss: 0.2079 - acc: 0\n",
      "Epoch 504/1500\n",
      "1080/1080 [==============================] - 1s 744us/step - loss: 0.2207 - acc: 0.9204\n",
      "Epoch 505/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.6905 - acc: 0.7361\n",
      "Epoch 506/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.4166 - acc: 0.8269\n",
      "Epoch 507/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.5459 - acc: 0.7833\n",
      "Epoch 508/1500\n",
      "1080/1080 [==============================] - 1s 751us/step - loss: 0.2399 - acc: 0.9056\n",
      "Epoch 509/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.2106 - acc: 0.9269\n",
      "Epoch 510/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.2247 - acc: 0.9148\n",
      "Epoch 511/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.2025 - acc: 0.9306\n",
      "Epoch 512/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.2138 - acc: 0.9259\n",
      "Epoch 513/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.2226 - acc: 0.9176\n",
      "Epoch 514/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.1929 - acc: 0.9306\n",
      "Epoch 515/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.1913 - acc: 0.9324\n",
      "Epoch 516/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.1992 - acc: 0.9287\n",
      "Epoch 517/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.2344 - acc: 0.9148\n",
      "Epoch 518/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.1903 - acc: 0.9361\n",
      "Epoch 519/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.1853 - acc: 0.9333\n",
      "Epoch 520/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.1854 - acc: 0.9361\n",
      "Epoch 521/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.2307 - acc: 0.9102 0s - loss: 0.2077 - acc: 0\n",
      "Epoch 522/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.2748 - acc: 0.8889\n",
      "Epoch 523/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.2214 - acc: 0.9204\n",
      "Epoch 524/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.2599 - acc: 0.8898\n",
      "Epoch 525/1500\n",
      "1080/1080 [==============================] - 1s 784us/step - loss: 0.2150 - acc: 0.9185\n",
      "Epoch 526/1500\n",
      "1080/1080 [==============================] - 1s 741us/step - loss: 0.2180 - acc: 0.9185\n",
      "Epoch 527/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.3315 - acc: 0.8769\n",
      "Epoch 528/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.4431 - acc: 0.8269\n",
      "Epoch 529/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.2771 - acc: 0.8870\n",
      "Epoch 530/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.3225 - acc: 0.8741\n",
      "Epoch 531/1500\n",
      "1080/1080 [==============================] - 1s 685us/step - loss: 0.2223 - acc: 0.9130\n",
      "Epoch 532/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1794 - acc: 0.9324\n",
      "Epoch 533/1500\n",
      "1080/1080 [==============================] - 1s 750us/step - loss: 0.1786 - acc: 0.9398\n",
      "Epoch 534/1500\n",
      "1080/1080 [==============================] - 1s 764us/step - loss: 0.2214 - acc: 0.9102\n",
      "Epoch 535/1500\n",
      "1080/1080 [==============================] - 1s 724us/step - loss: 0.1955 - acc: 0.9315\n",
      "Epoch 536/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.2059 - acc: 0.9213\n",
      "Epoch 537/1500\n",
      "1080/1080 [==============================] - 1s 732us/step - loss: 0.3222 - acc: 0.8593\n",
      "Epoch 538/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1848 - acc: 0.9389\n",
      "Epoch 539/1500\n",
      "1080/1080 [==============================] - 1s 716us/step - loss: 0.1843 - acc: 0.9287\n",
      "Epoch 540/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.1838 - acc: 0.9324\n",
      "Epoch 541/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.2074 - acc: 0.9185\n",
      "Epoch 542/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1756 - acc: 0.9370\n",
      "Epoch 543/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1671 - acc: 0.9435\n",
      "Epoch 544/1500\n",
      "1080/1080 [==============================] - 1s 718us/step - loss: 0.2064 - acc: 0.9204\n",
      "Epoch 545/1500\n",
      "1080/1080 [==============================] - 1s 718us/step - loss: 0.2440 - acc: 0.9074 0s - loss: 0.2209 - acc: 0.\n",
      "Epoch 546/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.2105 - acc: 0.9222\n",
      "Epoch 547/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.4105 - acc: 0.8537\n",
      "Epoch 548/1500\n",
      "1080/1080 [==============================] - 1s 715us/step - loss: 1.1442 - acc: 0.6574\n",
      "Epoch 549/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.6177 - acc: 0.7898\n",
      "Epoch 550/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.2623 - acc: 0.9065\n",
      "Epoch 551/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.2909 - acc: 0.8769\n",
      "Epoch 552/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.2512 - acc: 0.8926\n",
      "Epoch 553/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.4392 - acc: 0.8167\n",
      "Epoch 554/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.2030 - acc: 0.9204\n",
      "Epoch 555/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.1822 - acc: 0.9315\n",
      "Epoch 556/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.1815 - acc: 0.9352\n",
      "Epoch 557/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.2335 - acc: 0.9074\n",
      "Epoch 558/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.2295 - acc: 0.9111\n",
      "Epoch 559/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.4049 - acc: 0.8259\n",
      "Epoch 560/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.2415 - acc: 0.8991\n",
      "Epoch 561/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.2029 - acc: 0.9269\n",
      "Epoch 562/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.1821 - acc: 0.9296\n",
      "Epoch 563/1500\n",
      "1080/1080 [==============================] - 1s 738us/step - loss: 0.5416 - acc: 0.8000\n",
      "Epoch 564/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.1852 - acc: 0.9352\n",
      "Epoch 565/1500\n",
      "1080/1080 [==============================] - 1s 597us/step - loss: 0.1840 - acc: 0.9343\n",
      "Epoch 566/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.1730 - acc: 0.9407\n",
      "Epoch 567/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.2692 - acc: 0.8917\n",
      "Epoch 568/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.2712 - acc: 0.8833\n",
      "Epoch 569/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.1689 - acc: 0.9417 0s - loss: 0.1946 - acc:\n",
      "Epoch 570/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.1800 - acc: 0.9426\n",
      "Epoch 571/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.1943 - acc: 0.9324\n",
      "Epoch 572/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.1794 - acc: 0.9491\n",
      "Epoch 573/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.1678 - acc: 0.9519\n",
      "Epoch 574/1500\n",
      "1080/1080 [==============================] - 1s 604us/step - loss: 0.1587 - acc: 0.9500\n",
      "Epoch 575/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1615 - acc: 0.9500\n",
      "Epoch 576/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.1808 - acc: 0.9398\n",
      "Epoch 577/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.1882 - acc: 0.9389\n",
      "Epoch 578/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.1705 - acc: 0.9463\n",
      "Epoch 579/1500\n",
      "1080/1080 [==============================] - 1s 600us/step - loss: 0.1975 - acc: 0.9333\n",
      "Epoch 580/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.1653 - acc: 0.9481\n",
      "Epoch 581/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.2943 - acc: 0.8898\n",
      "Epoch 582/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.2068 - acc: 0.9231\n",
      "Epoch 583/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.2447 - acc: 0.9102\n",
      "Epoch 584/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.6353 - acc: 0.7556\n",
      "Epoch 585/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.7218 - acc: 0.7380\n",
      "Epoch 586/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.4246 - acc: 0.8241\n",
      "Epoch 587/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.1933 - acc: 0.9231\n",
      "Epoch 588/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.1583 - acc: 0.9454\n",
      "Epoch 589/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.1589 - acc: 0.9417\n",
      "Epoch 590/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.1688 - acc: 0.9389\n",
      "Epoch 591/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.1796 - acc: 0.9407\n",
      "Epoch 592/1500\n",
      "1080/1080 [==============================] - 1s 603us/step - loss: 0.1601 - acc: 0.9537\n",
      "Epoch 593/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.1649 - acc: 0.9500\n",
      "Epoch 594/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.1724 - acc: 0.9370\n",
      "Epoch 595/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.2573 - acc: 0.9046\n",
      "Epoch 596/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.1503 - acc: 0.9481\n",
      "Epoch 597/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.1531 - acc: 0.9537 0s - loss: 0.1665 - acc:\n",
      "Epoch 598/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.1598 - acc: 0.9472\n",
      "Epoch 599/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.1477 - acc: 0.9546\n",
      "Epoch 600/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.1767 - acc: 0.9444\n",
      "Epoch 601/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.3546 - acc: 0.8676\n",
      "Epoch 602/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.4462 - acc: 0.8398\n",
      "Epoch 603/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.2077 - acc: 0.9241\n",
      "Epoch 604/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.1538 - acc: 0.9528\n",
      "Epoch 605/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.1838 - acc: 0.9343\n",
      "Epoch 606/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.3685 - acc: 0.8769 0s - loss: 0.1922 - acc: 0.93\n",
      "Epoch 607/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.6057 - acc: 0.7722\n",
      "Epoch 608/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.1851 - acc: 0.9315\n",
      "Epoch 609/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.1485 - acc: 0.9537\n",
      "Epoch 610/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.1445 - acc: 0.9574\n",
      "Epoch 611/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.1434 - acc: 0.9565\n",
      "Epoch 612/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.1598 - acc: 0.9472\n",
      "Epoch 613/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.1635 - acc: 0.9463\n",
      "Epoch 614/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.2717 - acc: 0.8917\n",
      "Epoch 615/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.2463 - acc: 0.9019\n",
      "Epoch 616/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.1729 - acc: 0.9398 0s - loss: 0.1532 - acc: 0.9\n",
      "Epoch 617/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.1435 - acc: 0.9546\n",
      "Epoch 618/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.1479 - acc: 0.9583\n",
      "Epoch 619/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.1651 - acc: 0.9491\n",
      "Epoch 620/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.1637 - acc: 0.9472 0s - loss: 0.1246 - acc:\n",
      "Epoch 621/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.2258 - acc: 0.9139\n",
      "Epoch 622/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.1481 - acc: 0.9546\n",
      "Epoch 623/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.1435 - acc: 0.9583\n",
      "Epoch 624/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.1393 - acc: 0.9611\n",
      "Epoch 625/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.2066 - acc: 0.9269\n",
      "Epoch 626/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.1716 - acc: 0.9361\n",
      "Epoch 627/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.4748 - acc: 0.8111\n",
      "Epoch 628/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.5986 - acc: 0.7759\n",
      "Epoch 629/1500\n",
      "1080/1080 [==============================] - 1s 597us/step - loss: 0.6318 - acc: 0.7852\n",
      "Epoch 630/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.4508 - acc: 0.8130\n",
      "Epoch 631/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.1585 - acc: 0.9380\n",
      "Epoch 632/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.1529 - acc: 0.9444\n",
      "Epoch 633/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.1382 - acc: 0.9574\n",
      "Epoch 634/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.1500 - acc: 0.9509\n",
      "Epoch 635/1500\n",
      "1080/1080 [==============================] - 1s 706us/step - loss: 0.1404 - acc: 0.9593\n",
      "Epoch 636/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.1437 - acc: 0.9565 0s - loss: 0.1701 - acc\n",
      "Epoch 637/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.1732 - acc: 0.9361 0s - loss: 0.1284 - acc:\n",
      "Epoch 638/1500\n",
      "1080/1080 [==============================] - 1s 599us/step - loss: 0.1411 - acc: 0.9583\n",
      "Epoch 639/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1397 - acc: 0.9611\n",
      "Epoch 640/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.1373 - acc: 0.9611\n",
      "Epoch 641/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.1310 - acc: 0.9611\n",
      "Epoch 642/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.1348 - acc: 0.9611\n",
      "Epoch 643/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.1304 - acc: 0.9657\n",
      "Epoch 644/1500\n",
      "1080/1080 [==============================] - 1s 718us/step - loss: 0.1393 - acc: 0.9519\n",
      "Epoch 645/1500\n",
      "1080/1080 [==============================] - 1s 860us/step - loss: 0.1327 - acc: 0.9611\n",
      "Epoch 646/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.1348 - acc: 0.9574\n",
      "Epoch 647/1500\n",
      "1080/1080 [==============================] - 1s 720us/step - loss: 0.1248 - acc: 0.9639\n",
      "Epoch 648/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.1405 - acc: 0.9611\n",
      "Epoch 649/1500\n",
      "1080/1080 [==============================] - 1s 842us/step - loss: 0.2408 - acc: 0.9046 0s - loss: 0.1438 -\n",
      "Epoch 650/1500\n",
      "1080/1080 [==============================] - 1s 862us/step - loss: 0.6641 - acc: 0.7639\n",
      "Epoch 651/1500\n",
      "1080/1080 [==============================] - 1s 747us/step - loss: 0.3521 - acc: 0.8648\n",
      "Epoch 652/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.8575 - acc: 0.6963\n",
      "Epoch 653/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.3372 - acc: 0.8722\n",
      "Epoch 654/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.1975 - acc: 0.9361 0s - loss: 0.1935 - acc: 0.93\n",
      "Epoch 655/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.1707 - acc: 0.9389\n",
      "Epoch 656/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.1326 - acc: 0.9620\n",
      "Epoch 657/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1736 - acc: 0.9380\n",
      "Epoch 658/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.1364 - acc: 0.9574\n",
      "Epoch 659/1500\n",
      "1080/1080 [==============================] - 1s 738us/step - loss: 0.2374 - acc: 0.8981\n",
      "Epoch 660/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 0.1493 - acc: 0.9509\n",
      "Epoch 661/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.1296 - acc: 0.9657\n",
      "Epoch 662/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.1233 - acc: 0.9657\n",
      "Epoch 663/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.1311 - acc: 0.9657\n",
      "Epoch 664/1500\n",
      "1080/1080 [==============================] - 1s 711us/step - loss: 0.1337 - acc: 0.9648\n",
      "Epoch 665/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.1715 - acc: 0.9463\n",
      "Epoch 666/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1707 - acc: 0.9398\n",
      "Epoch 667/1500\n",
      "1080/1080 [==============================] - 1s 912us/step - loss: 1.0907 - acc: 0.6963\n",
      "Epoch 668/1500\n",
      "1080/1080 [==============================] - ETA: 0s - loss: 0.5520 - acc: 0.796 - 1s 719us/step - loss: 0.5364 - acc: 0.8037\n",
      "Epoch 669/1500\n",
      "1080/1080 [==============================] - 1s 739us/step - loss: 0.1541 - acc: 0.9509\n",
      "Epoch 670/1500\n",
      "1080/1080 [==============================] - 1s 761us/step - loss: 0.2431 - acc: 0.9046\n",
      "Epoch 671/1500\n",
      "1080/1080 [==============================] - 1s 740us/step - loss: 0.1720 - acc: 0.9398\n",
      "Epoch 672/1500\n",
      "1080/1080 [==============================] - 1s 737us/step - loss: 0.2052 - acc: 0.9231\n",
      "Epoch 673/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1474 - acc: 0.9583\n",
      "Epoch 674/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.1349 - acc: 0.9648\n",
      "Epoch 675/1500\n",
      "1080/1080 [==============================] - 1s 744us/step - loss: 0.1489 - acc: 0.9565\n",
      "Epoch 676/1500\n",
      "1080/1080 [==============================] - 1s 695us/step - loss: 0.1850 - acc: 0.9333\n",
      "Epoch 677/1500\n",
      "1080/1080 [==============================] - 1s 747us/step - loss: 0.1500 - acc: 0.9528\n",
      "Epoch 678/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1645 - acc: 0.9491\n",
      "Epoch 679/1500\n",
      "1080/1080 [==============================] - 1s 750us/step - loss: 0.2351 - acc: 0.9046\n",
      "Epoch 680/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1709 - acc: 0.9444\n",
      "Epoch 681/1500\n",
      "1080/1080 [==============================] - 1s 711us/step - loss: 0.1242 - acc: 0.9648\n",
      "Epoch 682/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.1651 - acc: 0.9500\n",
      "Epoch 683/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.1256 - acc: 0.9667\n",
      "Epoch 684/1500\n",
      "1080/1080 [==============================] - 1s 752us/step - loss: 0.1705 - acc: 0.9444\n",
      "Epoch 685/1500\n",
      "1080/1080 [==============================] - 1s 740us/step - loss: 0.3271 - acc: 0.8750\n",
      "Epoch 686/1500\n",
      "1080/1080 [==============================] - 1s 720us/step - loss: 0.1264 - acc: 0.9639\n",
      "Epoch 687/1500\n",
      "1080/1080 [==============================] - 1s 752us/step - loss: 0.1516 - acc: 0.9509\n",
      "Epoch 688/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.1850 - acc: 0.9426\n",
      "Epoch 689/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1986 - acc: 0.9296\n",
      "Epoch 690/1500\n",
      "1080/1080 [==============================] - 1s 720us/step - loss: 0.1206 - acc: 0.9685\n",
      "Epoch 691/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.1218 - acc: 0.9648\n",
      "Epoch 692/1500\n",
      "1080/1080 [==============================] - 1s 731us/step - loss: 0.1976 - acc: 0.9333\n",
      "Epoch 693/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1398 - acc: 0.9583\n",
      "Epoch 694/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.6274 - acc: 0.7833\n",
      "Epoch 695/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.4992 - acc: 0.8139\n",
      "Epoch 696/1500\n",
      "1080/1080 [==============================] - 1s 696us/step - loss: 0.1411 - acc: 0.9583\n",
      "Epoch 697/1500\n",
      "1080/1080 [==============================] - 1s 740us/step - loss: 0.1240 - acc: 0.9676\n",
      "Epoch 698/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.1284 - acc: 0.9620\n",
      "Epoch 699/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.1445 - acc: 0.9565\n",
      "Epoch 700/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.2256 - acc: 0.9074\n",
      "Epoch 701/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.2558 - acc: 0.8963\n",
      "Epoch 702/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.1746 - acc: 0.9361 0s - loss: 0.1930 - acc: 0\n",
      "Epoch 703/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1311 - acc: 0.9667\n",
      "Epoch 704/1500\n",
      "1080/1080 [==============================] - 1s 733us/step - loss: 0.1155 - acc: 0.9713\n",
      "Epoch 705/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.4197 - acc: 0.8259\n",
      "Epoch 706/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.3141 - acc: 0.8722 0s - loss: 0.3483 - acc: 0\n",
      "Epoch 707/1500\n",
      "1080/1080 [==============================] - 1s 757us/step - loss: 0.1918 - acc: 0.9278\n",
      "Epoch 708/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.1750 - acc: 0.9352\n",
      "Epoch 709/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.1203 - acc: 0.9620\n",
      "Epoch 710/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.1414 - acc: 0.9556\n",
      "Epoch 711/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.1443 - acc: 0.9556\n",
      "Epoch 712/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.1471 - acc: 0.9509\n",
      "Epoch 713/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.1213 - acc: 0.9657\n",
      "Epoch 714/1500\n",
      "1080/1080 [==============================] - 1s 739us/step - loss: 0.1095 - acc: 0.9731\n",
      "Epoch 715/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.1218 - acc: 0.9648 0s - loss: 0.1193 - acc: 0.9\n",
      "Epoch 716/1500\n",
      "1080/1080 [==============================] - 1s 744us/step - loss: 0.1178 - acc: 0.9657\n",
      "Epoch 717/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.1174 - acc: 0.9657\n",
      "Epoch 718/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.1548 - acc: 0.9528\n",
      "Epoch 719/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 0.1762 - acc: 0.9343 0s - loss: 0.0701 - \n",
      "Epoch 720/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.2775 - acc: 0.8852\n",
      "Epoch 721/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.1316 - acc: 0.9639\n",
      "Epoch 722/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.1106 - acc: 0.9704\n",
      "Epoch 723/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1098 - acc: 0.9713\n",
      "Epoch 724/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.1088 - acc: 0.9694\n",
      "Epoch 725/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.1191 - acc: 0.9685\n",
      "Epoch 726/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 0.1110 - acc: 0.9685\n",
      "Epoch 727/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.9440 - acc: 0.7296\n",
      "Epoch 728/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 1.2534 - acc: 0.6731\n",
      "Epoch 729/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.2284 - acc: 0.9102\n",
      "Epoch 730/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.1275 - acc: 0.9630\n",
      "Epoch 731/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.1233 - acc: 0.9639\n",
      "Epoch 732/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.1233 - acc: 0.9639\n",
      "Epoch 733/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.1475 - acc: 0.9565\n",
      "Epoch 734/1500\n",
      "1080/1080 [==============================] - 1s 710us/step - loss: 0.1222 - acc: 0.9694\n",
      "Epoch 735/1500\n",
      "1080/1080 [==============================] - 1s 710us/step - loss: 0.1214 - acc: 0.9620\n",
      "Epoch 736/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.1275 - acc: 0.9611\n",
      "Epoch 737/1500\n",
      "1080/1080 [==============================] - 1s 706us/step - loss: 0.1310 - acc: 0.9602\n",
      "Epoch 738/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1142 - acc: 0.9704\n",
      "Epoch 739/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.1168 - acc: 0.9667\n",
      "Epoch 740/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.1740 - acc: 0.9370\n",
      "Epoch 741/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1864 - acc: 0.9343\n",
      "Epoch 742/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.1933 - acc: 0.9259\n",
      "Epoch 743/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.2589 - acc: 0.9028\n",
      "Epoch 744/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.2144 - acc: 0.9241\n",
      "Epoch 745/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.1168 - acc: 0.9722\n",
      "Epoch 746/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.1104 - acc: 0.9694\n",
      "Epoch 747/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.1128 - acc: 0.9685\n",
      "Epoch 748/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 0.1177 - acc: 0.9657\n",
      "Epoch 749/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.1638 - acc: 0.9398\n",
      "Epoch 750/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.1284 - acc: 0.9602\n",
      "Epoch 751/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.1306 - acc: 0.9565\n",
      "Epoch 752/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.1842 - acc: 0.9324\n",
      "Epoch 753/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.1714 - acc: 0.9398\n",
      "Epoch 754/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.1067 - acc: 0.9704 0s - loss: 0.0939 - acc: 0\n",
      "Epoch 755/1500\n",
      "1080/1080 [==============================] - 1s 704us/step - loss: 0.1032 - acc: 0.9731\n",
      "Epoch 756/1500\n",
      "1080/1080 [==============================] - 1s 726us/step - loss: 0.1335 - acc: 0.9593 0s - loss: 0.1155 - acc\n",
      "Epoch 757/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.1251 - acc: 0.9611\n",
      "Epoch 758/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.1178 - acc: 0.9676\n",
      "Epoch 759/1500\n",
      "1080/1080 [==============================] - 1s 754us/step - loss: 0.1349 - acc: 0.9583\n",
      "Epoch 760/1500\n",
      "1080/1080 [==============================] - 1s 728us/step - loss: 0.1762 - acc: 0.9333\n",
      "Epoch 761/1500\n",
      "1080/1080 [==============================] - 1s 690us/step - loss: 0.1551 - acc: 0.9444\n",
      "Epoch 762/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.1018 - acc: 0.9731 0s - loss: 0.0704 - a\n",
      "Epoch 763/1500\n",
      "1080/1080 [==============================] - 1s 740us/step - loss: 0.1050 - acc: 0.9741\n",
      "Epoch 764/1500\n",
      "1080/1080 [==============================] - 1s 724us/step - loss: 0.3905 - acc: 0.8444\n",
      "Epoch 765/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1399 - acc: 0.9546\n",
      "Epoch 766/1500\n",
      "1080/1080 [==============================] - 1s 862us/step - loss: 0.1008 - acc: 0.9731\n",
      "Epoch 767/1500\n",
      "1080/1080 [==============================] - 1s 736us/step - loss: 0.1058 - acc: 0.9713\n",
      "Epoch 768/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.1095 - acc: 0.9731\n",
      "Epoch 769/1500\n",
      "1080/1080 [==============================] - 1s 683us/step - loss: 0.1393 - acc: 0.9519\n",
      "Epoch 770/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.4013 - acc: 0.8343\n",
      "Epoch 771/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.6857 - acc: 0.7685\n",
      "Epoch 772/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.2473 - acc: 0.9056\n",
      "Epoch 773/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.1274 - acc: 0.9657\n",
      "Epoch 774/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.1061 - acc: 0.9741\n",
      "Epoch 775/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.1024 - acc: 0.9722\n",
      "Epoch 776/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.1092 - acc: 0.9685\n",
      "Epoch 777/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.1541 - acc: 0.9481\n",
      "Epoch 778/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.3732 - acc: 0.8500\n",
      "Epoch 779/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.1075 - acc: 0.9741\n",
      "Epoch 780/1500\n",
      "1080/1080 [==============================] - 1s 793us/step - loss: 0.1053 - acc: 0.9741\n",
      "Epoch 781/1500\n",
      "1080/1080 [==============================] - 1s 803us/step - loss: 0.1030 - acc: 0.9731\n",
      "Epoch 782/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.1003 - acc: 0.9741\n",
      "Epoch 783/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 0.1008 - acc: 0.9713\n",
      "Epoch 784/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.1018 - acc: 0.9741\n",
      "Epoch 785/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1162 - acc: 0.9639\n",
      "Epoch 786/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.3479 - acc: 0.8648\n",
      "Epoch 787/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.2783 - acc: 0.8991\n",
      "Epoch 788/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.1046 - acc: 0.9713\n",
      "Epoch 789/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0953 - acc: 0.9750\n",
      "Epoch 790/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0978 - acc: 0.9769\n",
      "Epoch 791/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0984 - acc: 0.9769\n",
      "Epoch 792/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.1942 - acc: 0.9241\n",
      "Epoch 793/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.3325 - acc: 0.8630\n",
      "Epoch 794/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.1152 - acc: 0.9676\n",
      "Epoch 795/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0971 - acc: 0.9759\n",
      "Epoch 796/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.1029 - acc: 0.9722\n",
      "Epoch 797/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.1139 - acc: 0.9657\n",
      "Epoch 798/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0922 - acc: 0.9769\n",
      "Epoch 799/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.1039 - acc: 0.9731\n",
      "Epoch 800/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1038 - acc: 0.9713\n",
      "Epoch 801/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0897 - acc: 0.9769\n",
      "Epoch 802/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0982 - acc: 0.9713\n",
      "Epoch 803/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.1014 - acc: 0.9750\n",
      "Epoch 804/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0955 - acc: 0.9685\n",
      "Epoch 805/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 1.6128 - acc: 0.5972\n",
      "Epoch 806/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.3020 - acc: 0.8796\n",
      "Epoch 807/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.1260 - acc: 0.9667\n",
      "Epoch 808/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1025 - acc: 0.9713 0s - loss: 0.1022 - acc: 0.9\n",
      "Epoch 809/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.1035 - acc: 0.9722\n",
      "Epoch 810/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.0982 - acc: 0.9769\n",
      "Epoch 811/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0982 - acc: 0.9741\n",
      "Epoch 812/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0934 - acc: 0.9796\n",
      "Epoch 813/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.0937 - acc: 0.9778\n",
      "Epoch 814/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0957 - acc: 0.9731\n",
      "Epoch 815/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0923 - acc: 0.9759\n",
      "Epoch 816/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.1012 - acc: 0.9713\n",
      "Epoch 817/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0923 - acc: 0.9769\n",
      "Epoch 818/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.1008 - acc: 0.9741\n",
      "Epoch 819/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.1381 - acc: 0.9602 0s - loss: 0.1384 - acc: 0.\n",
      "Epoch 820/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.1253 - acc: 0.9583\n",
      "Epoch 821/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0890 - acc: 0.9759\n",
      "Epoch 822/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.0912 - acc: 0.9778\n",
      "Epoch 823/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0869 - acc: 0.9769\n",
      "Epoch 824/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.1198 - acc: 0.9630 0s - loss: 0.0938 - acc: 0\n",
      "Epoch 825/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.1249 - acc: 0.9602\n",
      "Epoch 826/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.5440 - acc: 0.8361\n",
      "Epoch 827/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.8000 - acc: 0.7537\n",
      "Epoch 828/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.2433 - acc: 0.9130\n",
      "Epoch 829/1500\n",
      "1080/1080 [==============================] - 1s 716us/step - loss: 0.1746 - acc: 0.9389\n",
      "Epoch 830/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1248 - acc: 0.9556\n",
      "Epoch 831/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0890 - acc: 0.9787 0s - loss: 0.0814 - acc: 0\n",
      "Epoch 832/1500\n",
      "1080/1080 [==============================] - 1s 711us/step - loss: 0.0905 - acc: 0.9759\n",
      "Epoch 833/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.0913 - acc: 0.9769\n",
      "Epoch 834/1500\n",
      "1080/1080 [==============================] - 1s 718us/step - loss: 0.0959 - acc: 0.9769\n",
      "Epoch 835/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.0863 - acc: 0.9778\n",
      "Epoch 836/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.0866 - acc: 0.9796\n",
      "Epoch 837/1500\n",
      "1080/1080 [==============================] - 1s 722us/step - loss: 0.0995 - acc: 0.9722\n",
      "Epoch 838/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.0990 - acc: 0.9722\n",
      "Epoch 839/1500\n",
      "1080/1080 [==============================] - 1s 778us/step - loss: 0.1136 - acc: 0.9657\n",
      "Epoch 840/1500\n",
      "1080/1080 [==============================] - 1s 734us/step - loss: 0.1627 - acc: 0.9435\n",
      "Epoch 841/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.1044 - acc: 0.9750\n",
      "Epoch 842/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.0856 - acc: 0.9787 0s - loss: 0.0744 - ac\n",
      "Epoch 843/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0831 - acc: 0.9778\n",
      "Epoch 844/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.0878 - acc: 0.9769\n",
      "Epoch 845/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.0836 - acc: 0.9759\n",
      "Epoch 846/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.0854 - acc: 0.9778\n",
      "Epoch 847/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0829 - acc: 0.9778\n",
      "Epoch 848/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.0836 - acc: 0.9769\n",
      "Epoch 849/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.0831 - acc: 0.9796\n",
      "Epoch 850/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0882 - acc: 0.9796\n",
      "Epoch 851/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.0910 - acc: 0.9778\n",
      "Epoch 852/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0839 - acc: 0.9787\n",
      "Epoch 853/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 0.1494 - acc: 0.9472\n",
      "Epoch 854/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.1198 - acc: 0.9648\n",
      "Epoch 855/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.0920 - acc: 0.9759\n",
      "Epoch 856/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0959 - acc: 0.9750\n",
      "Epoch 857/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.9033 - acc: 0.7722\n",
      "Epoch 858/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 1.4057 - acc: 0.6222\n",
      "Epoch 859/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.3702 - acc: 0.8602\n",
      "Epoch 860/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.1614 - acc: 0.9417\n",
      "Epoch 861/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.1662 - acc: 0.9435\n",
      "Epoch 862/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.2269 - acc: 0.9139\n",
      "Epoch 863/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.1095 - acc: 0.9722\n",
      "Epoch 864/1500\n",
      "1080/1080 [==============================] - 1s 603us/step - loss: 0.0884 - acc: 0.9815\n",
      "Epoch 865/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0913 - acc: 0.9806\n",
      "Epoch 866/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.1212 - acc: 0.9620\n",
      "Epoch 867/1500\n",
      "1080/1080 [==============================] - 1s 602us/step - loss: 0.0867 - acc: 0.9796\n",
      "Epoch 868/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.0864 - acc: 0.9806\n",
      "Epoch 869/1500\n",
      "1080/1080 [==============================] - 1s 599us/step - loss: 0.0879 - acc: 0.9787\n",
      "Epoch 870/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0891 - acc: 0.9787\n",
      "Epoch 871/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.0840 - acc: 0.9815\n",
      "Epoch 872/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0949 - acc: 0.9769\n",
      "Epoch 873/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0834 - acc: 0.9806\n",
      "Epoch 874/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0814 - acc: 0.9806\n",
      "Epoch 875/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0830 - acc: 0.9815\n",
      "Epoch 876/1500\n",
      "1080/1080 [==============================] - 1s 598us/step - loss: 0.0799 - acc: 0.9796\n",
      "Epoch 877/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0812 - acc: 0.9796\n",
      "Epoch 878/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0773 - acc: 0.9806\n",
      "Epoch 879/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0861 - acc: 0.9796\n",
      "Epoch 880/1500\n",
      "1080/1080 [==============================] - 1s 594us/step - loss: 0.4256 - acc: 0.8611\n",
      "Epoch 881/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.1353 - acc: 0.9602\n",
      "Epoch 882/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0822 - acc: 0.9796\n",
      "Epoch 883/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0819 - acc: 0.9796\n",
      "Epoch 884/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0922 - acc: 0.9769\n",
      "Epoch 885/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.0860 - acc: 0.9778\n",
      "Epoch 886/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0816 - acc: 0.9796\n",
      "Epoch 887/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0804 - acc: 0.9796\n",
      "Epoch 888/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0766 - acc: 0.9806\n",
      "Epoch 889/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.0958 - acc: 0.9704\n",
      "Epoch 890/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.1181 - acc: 0.9657\n",
      "Epoch 891/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0831 - acc: 0.9778\n",
      "Epoch 892/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0820 - acc: 0.9787\n",
      "Epoch 893/1500\n",
      "1080/1080 [==============================] - 1s 612us/step - loss: 0.0809 - acc: 0.9806\n",
      "Epoch 894/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.3266 - acc: 0.8907\n",
      "Epoch 895/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 1.0744 - acc: 0.6843\n",
      "Epoch 896/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.4133 - acc: 0.8481\n",
      "Epoch 897/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.1231 - acc: 0.9620\n",
      "Epoch 898/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.1073 - acc: 0.9713\n",
      "Epoch 899/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.1325 - acc: 0.9537\n",
      "Epoch 900/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.1415 - acc: 0.9481\n",
      "Epoch 901/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.0821 - acc: 0.9796\n",
      "Epoch 902/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0786 - acc: 0.9787\n",
      "Epoch 903/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0794 - acc: 0.9787\n",
      "Epoch 904/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0903 - acc: 0.9778\n",
      "Epoch 905/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.0835 - acc: 0.9796\n",
      "Epoch 906/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.0786 - acc: 0.9806\n",
      "Epoch 907/1500\n",
      "1080/1080 [==============================] - 1s 745us/step - loss: 0.0800 - acc: 0.9806\n",
      "Epoch 908/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0797 - acc: 0.9787\n",
      "Epoch 909/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0860 - acc: 0.9769\n",
      "Epoch 910/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0910 - acc: 0.9769\n",
      "Epoch 911/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0848 - acc: 0.9787\n",
      "Epoch 912/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0905 - acc: 0.9741\n",
      "Epoch 913/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0756 - acc: 0.9815\n",
      "Epoch 914/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0749 - acc: 0.9806 0s - loss: 0.0848 - acc: 0.9\n",
      "Epoch 915/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0769 - acc: 0.9815 0s - loss: 0.0768 - acc: 0.981\n",
      "Epoch 916/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.0887 - acc: 0.9778\n",
      "Epoch 917/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0766 - acc: 0.9796 0s - loss: 0.0828 - acc: 0.\n",
      "Epoch 918/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0776 - acc: 0.9806\n",
      "Epoch 919/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0732 - acc: 0.9806\n",
      "Epoch 920/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0767 - acc: 0.9796\n",
      "Epoch 921/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.0837 - acc: 0.9778\n",
      "Epoch 922/1500\n",
      "1080/1080 [==============================] - 1s 710us/step - loss: 0.0777 - acc: 0.9806\n",
      "Epoch 923/1500\n",
      "1080/1080 [==============================] - 1s 754us/step - loss: 0.0755 - acc: 0.9806\n",
      "Epoch 924/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0773 - acc: 0.9806\n",
      "Epoch 925/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0728 - acc: 0.9806\n",
      "Epoch 926/1500\n",
      "1080/1080 [==============================] - 1s 725us/step - loss: 0.0783 - acc: 0.9806\n",
      "Epoch 927/1500\n",
      "1080/1080 [==============================] - 1s 771us/step - loss: 0.0835 - acc: 0.9769\n",
      "Epoch 928/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.4411 - acc: 0.8528\n",
      "Epoch 929/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.9748 - acc: 0.7287\n",
      "Epoch 930/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.6816 - acc: 0.8046\n",
      "Epoch 931/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.1446 - acc: 0.9500 0s - loss: 0.1787 - acc: \n",
      "Epoch 932/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0868 - acc: 0.9778\n",
      "Epoch 933/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.1123 - acc: 0.9639\n",
      "Epoch 934/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.1114 - acc: 0.9676\n",
      "Epoch 935/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0835 - acc: 0.9759\n",
      "Epoch 936/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0784 - acc: 0.9796\n",
      "Epoch 937/1500\n",
      "1080/1080 [==============================] - 1s 701us/step - loss: 0.0797 - acc: 0.9796\n",
      "Epoch 938/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0796 - acc: 0.9796\n",
      "Epoch 939/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0749 - acc: 0.9796\n",
      "Epoch 940/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0813 - acc: 0.9787\n",
      "Epoch 941/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.1293 - acc: 0.9565\n",
      "Epoch 942/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.2335 - acc: 0.9139\n",
      "Epoch 943/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0801 - acc: 0.9796\n",
      "Epoch 944/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0754 - acc: 0.9806\n",
      "Epoch 945/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0842 - acc: 0.9769\n",
      "Epoch 946/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0963 - acc: 0.9741\n",
      "Epoch 947/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0801 - acc: 0.9787\n",
      "Epoch 948/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0763 - acc: 0.9815\n",
      "Epoch 949/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0749 - acc: 0.9806\n",
      "Epoch 950/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.0729 - acc: 0.9806\n",
      "Epoch 951/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0729 - acc: 0.9796\n",
      "Epoch 952/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0721 - acc: 0.9815\n",
      "Epoch 953/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.0743 - acc: 0.9806\n",
      "Epoch 954/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.0727 - acc: 0.9796\n",
      "Epoch 955/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0748 - acc: 0.9806 0s - loss: 0.0820 - acc: 0.\n",
      "Epoch 956/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0785 - acc: 0.9796\n",
      "Epoch 957/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.0701 - acc: 0.9815\n",
      "Epoch 958/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0692 - acc: 0.9815\n",
      "Epoch 959/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0913 - acc: 0.9787\n",
      "Epoch 960/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0898 - acc: 0.9741\n",
      "Epoch 961/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.3343 - acc: 0.8954\n",
      "Epoch 962/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.5966 - acc: 0.7963\n",
      "Epoch 963/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.3179 - acc: 0.8898\n",
      "Epoch 964/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0880 - acc: 0.9759\n",
      "Epoch 965/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0763 - acc: 0.9796\n",
      "Epoch 966/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.0720 - acc: 0.9806\n",
      "Epoch 967/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.0866 - acc: 0.9769\n",
      "Epoch 968/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.4176 - acc: 0.8537\n",
      "Epoch 969/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.1099 - acc: 0.9648\n",
      "Epoch 970/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0755 - acc: 0.9806\n",
      "Epoch 971/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.0757 - acc: 0.9787\n",
      "Epoch 972/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.4599 - acc: 0.8611\n",
      "Epoch 973/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.6749 - acc: 0.7778\n",
      "Epoch 974/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.1489 - acc: 0.9481 0s - loss: 0.1578 - acc: 0.9\n",
      "Epoch 975/1500\n",
      "1080/1080 [==============================] - 1s 608us/step - loss: 0.1306 - acc: 0.9556\n",
      "Epoch 976/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0814 - acc: 0.9796\n",
      "Epoch 977/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0790 - acc: 0.9806\n",
      "Epoch 978/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0774 - acc: 0.9815 0s - loss: 0.0825 - acc: 0.\n",
      "Epoch 979/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0753 - acc: 0.9796\n",
      "Epoch 980/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.1056 - acc: 0.9676\n",
      "Epoch 981/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0752 - acc: 0.9815\n",
      "Epoch 982/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0743 - acc: 0.9815\n",
      "Epoch 983/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0817 - acc: 0.9787\n",
      "Epoch 984/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0732 - acc: 0.9815\n",
      "Epoch 985/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0746 - acc: 0.9806\n",
      "Epoch 986/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0907 - acc: 0.9778\n",
      "Epoch 987/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0800 - acc: 0.9796\n",
      "Epoch 988/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0721 - acc: 0.9815\n",
      "Epoch 989/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0700 - acc: 0.9815\n",
      "Epoch 990/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0726 - acc: 0.9815\n",
      "Epoch 991/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0700 - acc: 0.9815\n",
      "Epoch 992/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0698 - acc: 0.9815\n",
      "Epoch 993/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.0724 - acc: 0.9815\n",
      "Epoch 994/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0682 - acc: 0.9815\n",
      "Epoch 995/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0690 - acc: 0.9815\n",
      "Epoch 996/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0678 - acc: 0.9815\n",
      "Epoch 997/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0711 - acc: 0.9815\n",
      "Epoch 998/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0833 - acc: 0.9778\n",
      "Epoch 999/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.1535 - acc: 0.9519\n",
      "Epoch 1000/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.1284 - acc: 0.9556\n",
      "Epoch 1001/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0743 - acc: 0.9806\n",
      "Epoch 1002/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0691 - acc: 0.9806\n",
      "Epoch 1003/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0713 - acc: 0.9815\n",
      "Epoch 1004/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0682 - acc: 0.9806\n",
      "Epoch 1005/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 1006/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0681 - acc: 0.9806\n",
      "Epoch 1007/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.0663 - acc: 0.9815\n",
      "Epoch 1008/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0710 - acc: 0.9796\n",
      "Epoch 1009/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0704 - acc: 0.9806\n",
      "Epoch 1010/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0658 - acc: 0.9815\n",
      "Epoch 1011/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0698 - acc: 0.9806\n",
      "Epoch 1012/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.0659 - acc: 0.9806\n",
      "Epoch 1013/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.0653 - acc: 0.9806\n",
      "Epoch 1014/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.0743 - acc: 0.9806\n",
      "Epoch 1015/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.0713 - acc: 0.9796\n",
      "Epoch 1016/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0648 - acc: 0.9815\n",
      "Epoch 1017/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 1018/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.0716 - acc: 0.9778\n",
      "Epoch 1019/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.7396 - acc: 0.7917\n",
      "Epoch 1020/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.6405 - acc: 0.7861\n",
      "Epoch 1021/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.3331 - acc: 0.8861\n",
      "Epoch 1022/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.5836 - acc: 0.8065\n",
      "Epoch 1023/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.2121 - acc: 0.9185\n",
      "Epoch 1024/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.1344 - acc: 0.9509\n",
      "Epoch 1025/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0764 - acc: 0.9778\n",
      "Epoch 1026/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0722 - acc: 0.9806\n",
      "Epoch 1027/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0822 - acc: 0.9796\n",
      "Epoch 1028/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0698 - acc: 0.9815\n",
      "Epoch 1029/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0686 - acc: 0.9815\n",
      "Epoch 1030/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0671 - acc: 0.9815\n",
      "Epoch 1031/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0665 - acc: 0.9815\n",
      "Epoch 1032/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0670 - acc: 0.9806\n",
      "Epoch 1033/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.0694 - acc: 0.9806\n",
      "Epoch 1034/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0710 - acc: 0.9806 0s - loss: 0.0766 - acc: 0\n",
      "Epoch 1035/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0678 - acc: 0.9815\n",
      "Epoch 1036/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0704 - acc: 0.9815\n",
      "Epoch 1037/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0694 - acc: 0.9815\n",
      "Epoch 1038/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0728 - acc: 0.9815\n",
      "Epoch 1039/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0861 - acc: 0.9759\n",
      "Epoch 1040/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.1621 - acc: 0.9426\n",
      "Epoch 1041/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.0978 - acc: 0.9722\n",
      "Epoch 1042/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0690 - acc: 0.9806\n",
      "Epoch 1043/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.0667 - acc: 0.9806\n",
      "Epoch 1044/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0672 - acc: 0.9815 0s - loss: 0.0578 - acc: 0.9\n",
      "Epoch 1045/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0661 - acc: 0.9815\n",
      "Epoch 1046/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0663 - acc: 0.9815\n",
      "Epoch 1047/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0693 - acc: 0.9815\n",
      "Epoch 1048/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0652 - acc: 0.9815\n",
      "Epoch 1049/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0654 - acc: 0.9815\n",
      "Epoch 1050/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0653 - acc: 0.9815\n",
      "Epoch 1051/1500\n",
      "1080/1080 [==============================] - 1s 762us/step - loss: 0.0653 - acc: 0.9815\n",
      "Epoch 1052/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.0753 - acc: 0.9806\n",
      "Epoch 1053/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.0700 - acc: 0.9796\n",
      "Epoch 1054/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.0640 - acc: 0.9815\n",
      "Epoch 1055/1500\n",
      "1080/1080 [==============================] - 1s 622us/step - loss: 0.0897 - acc: 0.9769\n",
      "Epoch 1056/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0665 - acc: 0.9815\n",
      "Epoch 1057/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.1940 - acc: 0.9231\n",
      "Epoch 1058/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.8390 - acc: 0.7519\n",
      "Epoch 1059/1500\n",
      "1080/1080 [==============================] - 1s 602us/step - loss: 0.5170 - acc: 0.8426\n",
      "Epoch 1060/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.7994 - acc: 0.7472\n",
      "Epoch 1061/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.1923 - acc: 0.9343\n",
      "Epoch 1062/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.1019 - acc: 0.9667\n",
      "Epoch 1063/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.0745 - acc: 0.9806\n",
      "Epoch 1064/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0717 - acc: 0.9806\n",
      "Epoch 1065/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.1151 - acc: 0.9583\n",
      "Epoch 1066/1500\n",
      "1080/1080 [==============================] - 1s 727us/step - loss: 0.0855 - acc: 0.9769\n",
      "Epoch 1067/1500\n",
      "1080/1080 [==============================] - 1s 695us/step - loss: 0.0718 - acc: 0.9815\n",
      "Epoch 1068/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0678 - acc: 0.9815\n",
      "Epoch 1069/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0700 - acc: 0.9806\n",
      "Epoch 1070/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.0664 - acc: 0.9806\n",
      "Epoch 1071/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0680 - acc: 0.9815\n",
      "Epoch 1072/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0688 - acc: 0.9806\n",
      "Epoch 1073/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.0706 - acc: 0.9806\n",
      "Epoch 1074/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0660 - acc: 0.9815\n",
      "Epoch 1075/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.0668 - acc: 0.9815\n",
      "Epoch 1076/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.0680 - acc: 0.9815\n",
      "Epoch 1077/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0646 - acc: 0.9815\n",
      "Epoch 1078/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0650 - acc: 0.9815\n",
      "Epoch 1079/1500\n",
      "1080/1080 [==============================] - 1s 680us/step - loss: 0.0666 - acc: 0.9806\n",
      "Epoch 1080/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.0641 - acc: 0.9815\n",
      "Epoch 1081/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1082/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0639 - acc: 0.9815\n",
      "Epoch 1083/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.0638 - acc: 0.9815\n",
      "Epoch 1084/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 1085/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0659 - acc: 0.9815\n",
      "Epoch 1086/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0642 - acc: 0.9815\n",
      "Epoch 1087/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.0654 - acc: 0.9815\n",
      "Epoch 1088/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0651 - acc: 0.9815\n",
      "Epoch 1089/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0684 - acc: 0.9815\n",
      "Epoch 1090/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.0656 - acc: 0.9815\n",
      "Epoch 1091/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0626 - acc: 0.9815\n",
      "Epoch 1092/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0632 - acc: 0.9815\n",
      "Epoch 1093/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0737 - acc: 0.9806\n",
      "Epoch 1094/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.0630 - acc: 0.9815\n",
      "Epoch 1095/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.0641 - acc: 0.9815\n",
      "Epoch 1096/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 643us/step - loss: 1.0981 - acc: 0.7417\n",
      "Epoch 1097/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 1.3303 - acc: 0.6657\n",
      "Epoch 1098/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 2.2863 - acc: 0.5269\n",
      "Epoch 1099/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 1.4550 - acc: 0.6463\n",
      "Epoch 1100/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.4041 - acc: 0.8787\n",
      "Epoch 1101/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.1064 - acc: 0.9722\n",
      "Epoch 1102/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0994 - acc: 0.9731\n",
      "Epoch 1103/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0957 - acc: 0.9759\n",
      "Epoch 1104/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0872 - acc: 0.9778\n",
      "Epoch 1105/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0795 - acc: 0.9806\n",
      "Epoch 1106/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0823 - acc: 0.9806\n",
      "Epoch 1107/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0770 - acc: 0.9815\n",
      "Epoch 1108/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0753 - acc: 0.9815\n",
      "Epoch 1109/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.1156 - acc: 0.9657\n",
      "Epoch 1110/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0849 - acc: 0.9778\n",
      "Epoch 1111/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0736 - acc: 0.9815\n",
      "Epoch 1112/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0739 - acc: 0.9806\n",
      "Epoch 1113/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0721 - acc: 0.9815\n",
      "Epoch 1114/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0690 - acc: 0.9815\n",
      "Epoch 1115/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0703 - acc: 0.9815\n",
      "Epoch 1116/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0756 - acc: 0.9796\n",
      "Epoch 1117/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0686 - acc: 0.9815 0s - loss: 0.0763 - acc: 0.9\n",
      "Epoch 1118/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.0740 - acc: 0.9806\n",
      "Epoch 1119/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0723 - acc: 0.9815\n",
      "Epoch 1120/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0678 - acc: 0.9815\n",
      "Epoch 1121/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0681 - acc: 0.9815\n",
      "Epoch 1122/1500\n",
      "1080/1080 [==============================] - ETA: 0s - loss: 0.0743 - acc: 0.979 - 1s 652us/step - loss: 0.0703 - acc: 0.9815\n",
      "Epoch 1123/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.0694 - acc: 0.9815\n",
      "Epoch 1124/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0673 - acc: 0.9815\n",
      "Epoch 1125/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0674 - acc: 0.9815\n",
      "Epoch 1126/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0659 - acc: 0.9815\n",
      "Epoch 1127/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0674 - acc: 0.9815\n",
      "Epoch 1128/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0762 - acc: 0.9815\n",
      "Epoch 1129/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0697 - acc: 0.9815\n",
      "Epoch 1130/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0843 - acc: 0.9759\n",
      "Epoch 1131/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 1.2727 - acc: 0.6759\n",
      "Epoch 1132/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.3411 - acc: 0.8685\n",
      "Epoch 1133/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0960 - acc: 0.9722\n",
      "Epoch 1134/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0811 - acc: 0.9769\n",
      "Epoch 1135/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0753 - acc: 0.9806\n",
      "Epoch 1136/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0734 - acc: 0.9806\n",
      "Epoch 1137/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0698 - acc: 0.9815\n",
      "Epoch 1138/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0712 - acc: 0.9815\n",
      "Epoch 1139/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0694 - acc: 0.9815\n",
      "Epoch 1140/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0679 - acc: 0.9815\n",
      "Epoch 1141/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.0675 - acc: 0.9815\n",
      "Epoch 1142/1500\n",
      "1080/1080 [==============================] - 1s 678us/step - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 1143/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0691 - acc: 0.9815\n",
      "Epoch 1144/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.0667 - acc: 0.9815\n",
      "Epoch 1145/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0797 - acc: 0.9806\n",
      "Epoch 1146/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0698 - acc: 0.9815\n",
      "Epoch 1147/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0662 - acc: 0.9815 0s - loss: 0.0616 - acc: 0\n",
      "Epoch 1148/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0682 - acc: 0.9815\n",
      "Epoch 1149/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0677 - acc: 0.9815\n",
      "Epoch 1150/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 1151/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0654 - acc: 0.9815\n",
      "Epoch 1152/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0654 - acc: 0.9815\n",
      "Epoch 1153/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 1154/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.0651 - acc: 0.9815\n",
      "Epoch 1155/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0658 - acc: 0.9815 0s - loss: 0.0748 - ac\n",
      "Epoch 1156/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 1157/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1158/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0649 - acc: 0.9815\n",
      "Epoch 1159/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1160/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0641 - acc: 0.9815\n",
      "Epoch 1161/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0643 - acc: 0.9815\n",
      "Epoch 1162/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0639 - acc: 0.9815\n",
      "Epoch 1163/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0635 - acc: 0.9815\n",
      "Epoch 1164/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.0628 - acc: 0.9815\n",
      "Epoch 1165/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.0802 - acc: 0.9778\n",
      "Epoch 1166/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.0678 - acc: 0.9815\n",
      "Epoch 1167/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0777 - acc: 0.9796\n",
      "Epoch 1168/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0672 - acc: 0.9815 0s - loss: 0.0566 - acc: 0\n",
      "Epoch 1169/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0817 - acc: 0.9787\n",
      "Epoch 1170/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.4027 - acc: 0.8370\n",
      "Epoch 1171/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.4964 - acc: 0.8463\n",
      "Epoch 1172/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.4481 - acc: 0.8398\n",
      "Epoch 1173/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.4516 - acc: 0.8519\n",
      "Epoch 1174/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.1059 - acc: 0.9667\n",
      "Epoch 1175/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0683 - acc: 0.9815\n",
      "Epoch 1176/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0730 - acc: 0.9806\n",
      "Epoch 1177/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0722 - acc: 0.9815\n",
      "Epoch 1178/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0659 - acc: 0.9815\n",
      "Epoch 1179/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0637 - acc: 0.9815\n",
      "Epoch 1180/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.0654 - acc: 0.9815\n",
      "Epoch 1181/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0670 - acc: 0.9815\n",
      "Epoch 1182/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0646 - acc: 0.9815 0s - loss: 0.0788 - acc: \n",
      "Epoch 1183/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0690 - acc: 0.9815\n",
      "Epoch 1184/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 1185/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0745 - acc: 0.9815\n",
      "Epoch 1186/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0700 - acc: 0.9806\n",
      "Epoch 1187/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0637 - acc: 0.9815\n",
      "Epoch 1188/1500\n",
      "1080/1080 [==============================] - 1s 614us/step - loss: 0.0950 - acc: 0.9741\n",
      "Epoch 1189/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.0706 - acc: 0.9787 0s - loss: 0.0743 - acc: 0.\n",
      "Epoch 1190/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0626 - acc: 0.9815\n",
      "Epoch 1191/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.0619 - acc: 0.9815\n",
      "Epoch 1192/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.0616 - acc: 0.9815\n",
      "Epoch 1193/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0638 - acc: 0.9815\n",
      "Epoch 1194/1500\n",
      "1080/1080 [==============================] - 1s 602us/step - loss: 0.0624 - acc: 0.9815\n",
      "Epoch 1195/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.0606 - acc: 0.9815\n",
      "Epoch 1196/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.0615 - acc: 0.9815\n",
      "Epoch 1197/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0606 - acc: 0.9815\n",
      "Epoch 1198/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1199/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0884 - acc: 0.9750\n",
      "Epoch 1200/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0727 - acc: 0.9806\n",
      "Epoch 1201/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 0.0640 - acc: 0.9815\n",
      "Epoch 1202/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0621 - acc: 0.9815\n",
      "Epoch 1203/1500\n",
      "1080/1080 [==============================] - 1s 603us/step - loss: 0.0593 - acc: 0.9815\n",
      "Epoch 1204/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.0595 - acc: 0.9815\n",
      "Epoch 1205/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.0597 - acc: 0.9815\n",
      "Epoch 1206/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0611 - acc: 0.9815\n",
      "Epoch 1207/1500\n",
      "1080/1080 [==============================] - 1s 671us/step - loss: 0.0619 - acc: 0.9815\n",
      "Epoch 1208/1500\n",
      "1080/1080 [==============================] - 1s 744us/step - loss: 0.0672 - acc: 0.9778\n",
      "Epoch 1209/1500\n",
      "1080/1080 [==============================] - 1s 685us/step - loss: 0.9154 - acc: 0.7241 0s - loss: 0.6620 - acc\n",
      "Epoch 1210/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.5706 - acc: 0.8231\n",
      "Epoch 1211/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.2955 - acc: 0.9074\n",
      "Epoch 1212/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.0692 - acc: 0.9796\n",
      "Epoch 1213/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0884 - acc: 0.9741\n",
      "Epoch 1214/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0715 - acc: 0.9778\n",
      "Epoch 1215/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0648 - acc: 0.9815\n",
      "Epoch 1216/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0636 - acc: 0.9815\n",
      "Epoch 1217/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0674 - acc: 0.9815\n",
      "Epoch 1218/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0665 - acc: 0.9815\n",
      "Epoch 1219/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0641 - acc: 0.9815\n",
      "Epoch 1220/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0638 - acc: 0.9815\n",
      "Epoch 1221/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1222/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0629 - acc: 0.9815\n",
      "Epoch 1223/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1224/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0613 - acc: 0.9815\n",
      "Epoch 1225/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0615 - acc: 0.9815\n",
      "Epoch 1226/1500\n",
      "1080/1080 [==============================] - ETA: 0s - loss: 0.0631 - acc: 0.981 - 1s 638us/step - loss: 0.0621 - acc: 0.9815\n",
      "Epoch 1227/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0603 - acc: 0.9815\n",
      "Epoch 1228/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0633 - acc: 0.9815\n",
      "Epoch 1229/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0659 - acc: 0.9806\n",
      "Epoch 1230/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0639 - acc: 0.9815\n",
      "Epoch 1231/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.0611 - acc: 0.9815\n",
      "Epoch 1232/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0620 - acc: 0.9815\n",
      "Epoch 1233/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0648 - acc: 0.9815\n",
      "Epoch 1234/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0604 - acc: 0.9815\n",
      "Epoch 1235/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0589 - acc: 0.9815\n",
      "Epoch 1236/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.0590 - acc: 0.9815\n",
      "Epoch 1237/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.0579 - acc: 0.9815\n",
      "Epoch 1238/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0591 - acc: 0.9815\n",
      "Epoch 1239/1500\n",
      "1080/1080 [==============================] - 1s 656us/step - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 1240/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.0739 - acc: 0.9796\n",
      "Epoch 1241/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 1.1152 - acc: 0.7472\n",
      "Epoch 1242/1500\n",
      "1080/1080 [==============================] - 1s 597us/step - loss: 0.4860 - acc: 0.8269\n",
      "Epoch 1243/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 1.7702 - acc: 0.5954\n",
      "Epoch 1244/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.7906 - acc: 0.7685\n",
      "Epoch 1245/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.1224 - acc: 0.9546\n",
      "Epoch 1246/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0761 - acc: 0.9796\n",
      "Epoch 1247/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0703 - acc: 0.9806\n",
      "Epoch 1248/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0669 - acc: 0.9815\n",
      "Epoch 1249/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0684 - acc: 0.9815\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0650 - acc: 0.9815\n",
      "Epoch 1251/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.0650 - acc: 0.9815 0s - loss: 0.0637 - acc: 0.98\n",
      "Epoch 1252/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0692 - acc: 0.9806\n",
      "Epoch 1253/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0662 - acc: 0.9815\n",
      "Epoch 1254/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0632 - acc: 0.9815\n",
      "Epoch 1255/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0631 - acc: 0.9815\n",
      "Epoch 1256/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0618 - acc: 0.9815\n",
      "Epoch 1257/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0625 - acc: 0.9815\n",
      "Epoch 1258/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0625 - acc: 0.9815\n",
      "Epoch 1259/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0617 - acc: 0.9815\n",
      "Epoch 1260/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0625 - acc: 0.9815\n",
      "Epoch 1261/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.0612 - acc: 0.9815\n",
      "Epoch 1262/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1263/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0609 - acc: 0.9815\n",
      "Epoch 1264/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0617 - acc: 0.9815\n",
      "Epoch 1265/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0605 - acc: 0.9815\n",
      "Epoch 1266/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0626 - acc: 0.9815\n",
      "Epoch 1267/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0609 - acc: 0.9815\n",
      "Epoch 1268/1500\n",
      "1080/1080 [==============================] - 1s 636us/step - loss: 0.0611 - acc: 0.9815\n",
      "Epoch 1269/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1270/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0595 - acc: 0.9815\n",
      "Epoch 1271/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0609 - acc: 0.9815\n",
      "Epoch 1272/1500\n",
      "1080/1080 [==============================] - 1s 697us/step - loss: 0.0620 - acc: 0.9815\n",
      "Epoch 1273/1500\n",
      "1080/1080 [==============================] - 1s 754us/step - loss: 0.0611 - acc: 0.9815\n",
      "Epoch 1274/1500\n",
      "1080/1080 [==============================] - 1s 808us/step - loss: 0.0606 - acc: 0.9815 0s - loss: 0.0647 - acc\n",
      "Epoch 1275/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.0589 - acc: 0.9815\n",
      "Epoch 1276/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.0603 - acc: 0.9815\n",
      "Epoch 1277/1500\n",
      "1080/1080 [==============================] - 1s 708us/step - loss: 0.0600 - acc: 0.9815\n",
      "Epoch 1278/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.0605 - acc: 0.9815\n",
      "Epoch 1279/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.0593 - acc: 0.9815\n",
      "Epoch 1280/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1281/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1282/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 1283/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.0586 - acc: 0.9815\n",
      "Epoch 1284/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.0597 - acc: 0.9815\n",
      "Epoch 1285/1500\n",
      "1080/1080 [==============================] - 1s 681us/step - loss: 0.0721 - acc: 0.9806\n",
      "Epoch 1286/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.4943 - acc: 0.8296\n",
      "Epoch 1287/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.1053 - acc: 0.9657\n",
      "Epoch 1288/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0621 - acc: 0.9815\n",
      "Epoch 1289/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0671 - acc: 0.9806\n",
      "Epoch 1290/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0596 - acc: 0.9815\n",
      "Epoch 1291/1500\n",
      "1080/1080 [==============================] - 1s 659us/step - loss: 0.0629 - acc: 0.9815\n",
      "Epoch 1292/1500\n",
      "1080/1080 [==============================] - 1s 655us/step - loss: 0.0655 - acc: 0.9815\n",
      "Epoch 1293/1500\n",
      "1080/1080 [==============================] - 1s 682us/step - loss: 0.0629 - acc: 0.9815\n",
      "Epoch 1294/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.0585 - acc: 0.9815\n",
      "Epoch 1295/1500\n",
      "1080/1080 [==============================] - 1s 712us/step - loss: 0.0586 - acc: 0.9815\n",
      "Epoch 1296/1500\n",
      "1080/1080 [==============================] - 1s 683us/step - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 1297/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.0616 - acc: 0.9815\n",
      "Epoch 1298/1500\n",
      "1080/1080 [==============================] - 1s 688us/step - loss: 0.0650 - acc: 0.9815\n",
      "Epoch 1299/1500\n",
      "1080/1080 [==============================] - 1s 705us/step - loss: 0.0593 - acc: 0.9815\n",
      "Epoch 1300/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0577 - acc: 0.9815\n",
      "Epoch 1301/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0577 - acc: 0.9815\n",
      "Epoch 1302/1500\n",
      "1080/1080 [==============================] - 1s 677us/step - loss: 0.0615 - acc: 0.9815\n",
      "Epoch 1303/1500\n",
      "1080/1080 [==============================] - 1s 703us/step - loss: 0.0594 - acc: 0.9815\n",
      "Epoch 1304/1500\n",
      "1080/1080 [==============================] - 1s 689us/step - loss: 0.0577 - acc: 0.9815\n",
      "Epoch 1305/1500\n",
      "1080/1080 [==============================] - 1s 694us/step - loss: 0.0612 - acc: 0.9815\n",
      "Epoch 1306/1500\n",
      "1080/1080 [==============================] - 1s 698us/step - loss: 1.3180 - acc: 0.7176\n",
      "Epoch 1307/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 1.0963 - acc: 0.6954 0s - loss: 1.4321 - ac\n",
      "Epoch 1308/1500\n",
      "1080/1080 [==============================] - 1s 685us/step - loss: 0.3509 - acc: 0.8787\n",
      "Epoch 1309/1500\n",
      "1080/1080 [==============================] - 1s 692us/step - loss: 0.0807 - acc: 0.9750\n",
      "Epoch 1310/1500\n",
      "1080/1080 [==============================] - 1s 674us/step - loss: 0.0669 - acc: 0.9815\n",
      "Epoch 1311/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0638 - acc: 0.9815\n",
      "Epoch 1312/1500\n",
      "1080/1080 [==============================] - 1s 707us/step - loss: 0.0625 - acc: 0.9815\n",
      "Epoch 1313/1500\n",
      "1080/1080 [==============================] - 1s 683us/step - loss: 0.0632 - acc: 0.9815\n",
      "Epoch 1314/1500\n",
      "1080/1080 [==============================] - 1s 714us/step - loss: 0.0672 - acc: 0.9815\n",
      "Epoch 1315/1500\n",
      "1080/1080 [==============================] - 1s 702us/step - loss: 0.0614 - acc: 0.9815\n",
      "Epoch 1316/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0646 - acc: 0.9815\n",
      "Epoch 1317/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0612 - acc: 0.9815\n",
      "Epoch 1318/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0614 - acc: 0.9815\n",
      "Epoch 1319/1500\n",
      "1080/1080 [==============================] - 1s 700us/step - loss: 0.0607 - acc: 0.9815\n",
      "Epoch 1320/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.0599 - acc: 0.9815\n",
      "Epoch 1321/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.0610 - acc: 0.9815\n",
      "Epoch 1322/1500\n",
      "1080/1080 [==============================] - 1s 691us/step - loss: 0.0605 - acc: 0.9815\n",
      "Epoch 1323/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0665 - acc: 0.9815\n",
      "Epoch 1324/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.0594 - acc: 0.9815\n",
      "Epoch 1325/1500\n",
      "1080/1080 [==============================] - 1s 699us/step - loss: 0.0597 - acc: 0.9815 0s - loss: 0.0573 - acc: 0.981\n",
      "Epoch 1326/1500\n",
      "1080/1080 [==============================] - 1s 687us/step - loss: 0.0610 - acc: 0.9815\n",
      "Epoch 1327/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0589 - acc: 0.9815\n",
      "Epoch 1328/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0584 - acc: 0.9815\n",
      "Epoch 1329/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0602 - acc: 0.9815 0s - loss: 0.0419 - acc: 0\n",
      "Epoch 1330/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0622 - acc: 0.9815\n",
      "Epoch 1331/1500\n",
      "1080/1080 [==============================] - 1s 740us/step - loss: 0.0658 - acc: 0.9815\n",
      "Epoch 1332/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0625 - acc: 0.9815\n",
      "Epoch 1333/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0586 - acc: 0.9815\n",
      "Epoch 1334/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0595 - acc: 0.9815\n",
      "Epoch 1335/1500\n",
      "1080/1080 [==============================] - 1s 623us/step - loss: 0.0602 - acc: 0.9815\n",
      "Epoch 1336/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0584 - acc: 0.9815\n",
      "Epoch 1337/1500\n",
      "1080/1080 [==============================] - 1s 605us/step - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 1338/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0580 - acc: 0.9815\n",
      "Epoch 1339/1500\n",
      "1080/1080 [==============================] - 1s 620us/step - loss: 0.0574 - acc: 0.9815\n",
      "Epoch 1340/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.0572 - acc: 0.9815\n",
      "Epoch 1341/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.0607 - acc: 0.9815\n",
      "Epoch 1342/1500\n",
      "1080/1080 [==============================] - 1s 607us/step - loss: 0.0645 - acc: 0.9815\n",
      "Epoch 1343/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0638 - acc: 0.9796\n",
      "Epoch 1344/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.7606 - acc: 0.8130\n",
      "Epoch 1345/1500\n",
      "1080/1080 [==============================] - 1s 606us/step - loss: 1.1689 - acc: 0.7028\n",
      "Epoch 1346/1500\n",
      "1080/1080 [==============================] - 1s 730us/step - loss: 0.3392 - acc: 0.8574\n",
      "Epoch 1347/1500\n",
      "1080/1080 [==============================] - 1s 733us/step - loss: 0.1020 - acc: 0.9630\n",
      "Epoch 1348/1500\n",
      "1080/1080 [==============================] - 1s 686us/step - loss: 0.1708 - acc: 0.9361\n",
      "Epoch 1349/1500\n",
      "1080/1080 [==============================] - 1s 684us/step - loss: 0.0969 - acc: 0.9722\n",
      "Epoch 1350/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.1250 - acc: 0.9583\n",
      "Epoch 1351/1500\n",
      "1080/1080 [==============================] - 1s 721us/step - loss: 0.0768 - acc: 0.9796\n",
      "Epoch 1352/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 1353/1500\n",
      "1080/1080 [==============================] - 1s 717us/step - loss: 0.0618 - acc: 0.9815\n",
      "Epoch 1354/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0612 - acc: 0.9815\n",
      "Epoch 1355/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0614 - acc: 0.9815\n",
      "Epoch 1356/1500\n",
      "1080/1080 [==============================] - 1s 719us/step - loss: 0.0597 - acc: 0.9815\n",
      "Epoch 1357/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0611 - acc: 0.9815\n",
      "Epoch 1358/1500\n",
      "1080/1080 [==============================] - 1s 675us/step - loss: 0.0592 - acc: 0.9815\n",
      "Epoch 1359/1500\n",
      "1080/1080 [==============================] - 1s 693us/step - loss: 0.0596 - acc: 0.9815\n",
      "Epoch 1360/1500\n",
      "1080/1080 [==============================] - 1s 665us/step - loss: 0.0607 - acc: 0.9815\n",
      "Epoch 1361/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0582 - acc: 0.9815\n",
      "Epoch 1362/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0588 - acc: 0.9815\n",
      "Epoch 1363/1500\n",
      "1080/1080 [==============================] - 1s 610us/step - loss: 0.0582 - acc: 0.9815\n",
      "Epoch 1364/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0586 - acc: 0.9815\n",
      "Epoch 1365/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0590 - acc: 0.9815\n",
      "Epoch 1366/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0597 - acc: 0.9815\n",
      "Epoch 1367/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0583 - acc: 0.9815\n",
      "Epoch 1368/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0587 - acc: 0.9815\n",
      "Epoch 1369/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0575 - acc: 0.9815\n",
      "Epoch 1370/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0583 - acc: 0.9815\n",
      "Epoch 1371/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0574 - acc: 0.9815\n",
      "Epoch 1372/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0569 - acc: 0.9815\n",
      "Epoch 1373/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0593 - acc: 0.9815\n",
      "Epoch 1374/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0591 - acc: 0.9815\n",
      "Epoch 1375/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0587 - acc: 0.9806\n",
      "Epoch 1376/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.0734 - acc: 0.9796\n",
      "Epoch 1377/1500\n",
      "1080/1080 [==============================] - 1s 638us/step - loss: 0.0622 - acc: 0.9815\n",
      "Epoch 1378/1500\n",
      "1080/1080 [==============================] - 1s 670us/step - loss: 0.0574 - acc: 0.9815\n",
      "Epoch 1379/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0563 - acc: 0.9815 0s - loss: 0.0512 - acc: \n",
      "Epoch 1380/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.0561 - acc: 0.9815\n",
      "Epoch 1381/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0580 - acc: 0.9815\n",
      "Epoch 1382/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0563 - acc: 0.9815\n",
      "Epoch 1383/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.0587 - acc: 0.9815\n",
      "Epoch 1384/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0565 - acc: 0.9815\n",
      "Epoch 1385/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0568 - acc: 0.9815\n",
      "Epoch 1386/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.0562 - acc: 0.9815\n",
      "Epoch 1387/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.8821 - acc: 0.8037\n",
      "Epoch 1388/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.5401 - acc: 0.8556\n",
      "Epoch 1389/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.1184 - acc: 0.9602\n",
      "Epoch 1390/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.1235 - acc: 0.9583\n",
      "Epoch 1391/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.1125 - acc: 0.9630\n",
      "Epoch 1392/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0675 - acc: 0.9806\n",
      "Epoch 1393/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0624 - acc: 0.9824\n",
      "Epoch 1394/1500\n",
      "1080/1080 [==============================] - 1s 667us/step - loss: 0.0600 - acc: 0.9815\n",
      "Epoch 1395/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0607 - acc: 0.9815\n",
      "Epoch 1396/1500\n",
      "1080/1080 [==============================] - 1s 673us/step - loss: 0.0599 - acc: 0.9824\n",
      "Epoch 1397/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0582 - acc: 0.9815\n",
      "Epoch 1398/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0570 - acc: 0.9815\n",
      "Epoch 1399/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0575 - acc: 0.9824\n",
      "Epoch 1400/1500\n",
      "1080/1080 [==============================] - 1s 679us/step - loss: 0.0577 - acc: 0.9815\n",
      "Epoch 1401/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0600 - acc: 0.9824\n",
      "Epoch 1402/1500\n",
      "1080/1080 [==============================] - 1s 666us/step - loss: 0.0567 - acc: 0.9824\n",
      "Epoch 1403/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0595 - acc: 0.9824\n",
      "Epoch 1404/1500\n",
      "1080/1080 [==============================] - 1s 644us/step - loss: 0.0598 - acc: 0.9824 0s - loss: 0.0524 - acc: 0\n",
      "Epoch 1405/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0613 - acc: 0.9824\n",
      "Epoch 1406/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0597 - acc: 0.9824\n",
      "Epoch 1407/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0592 - acc: 0.9815\n",
      "Epoch 1408/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0567 - acc: 0.9824\n",
      "Epoch 1409/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0567 - acc: 0.9824\n",
      "Epoch 1410/1500\n",
      "1080/1080 [==============================] - 1s 658us/step - loss: 0.0548 - acc: 0.9824\n",
      "Epoch 1411/1500\n",
      "1080/1080 [==============================] - 1s 624us/step - loss: 0.0552 - acc: 0.9824\n",
      "Epoch 1412/1500\n",
      "1080/1080 [==============================] - 1s 660us/step - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 1413/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 0.0624 - acc: 0.9815\n",
      "Epoch 1414/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 1415/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0557 - acc: 0.9824\n",
      "Epoch 1416/1500\n",
      "1080/1080 [==============================] - 1s 628us/step - loss: 0.0539 - acc: 0.9824\n",
      "Epoch 1417/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0589 - acc: 0.9824\n",
      "Epoch 1418/1500\n",
      "1080/1080 [==============================] - 1s 619us/step - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 1419/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0590 - acc: 0.9824\n",
      "Epoch 1420/1500\n",
      "1080/1080 [==============================] - 1s 617us/step - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 1421/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0539 - acc: 0.9824\n",
      "Epoch 1422/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0542 - acc: 0.9824\n",
      "Epoch 1423/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0539 - acc: 0.9824\n",
      "Epoch 1424/1500\n",
      "1080/1080 [==============================] - 1s 643us/step - loss: 0.0550 - acc: 0.9824\n",
      "Epoch 1425/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.0551 - acc: 0.9824\n",
      "Epoch 1426/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0534 - acc: 0.9824\n",
      "Epoch 1427/1500\n",
      "1080/1080 [==============================] - 1s 609us/step - loss: 0.0534 - acc: 0.9824\n",
      "Epoch 1428/1500\n",
      "1080/1080 [==============================] - 1s 616us/step - loss: 0.0597 - acc: 0.9824\n",
      "Epoch 1429/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.3049 - acc: 0.9093\n",
      "Epoch 1430/1500\n",
      "1080/1080 [==============================] - 1s 642us/step - loss: 0.5966 - acc: 0.8287\n",
      "Epoch 1431/1500\n",
      "1080/1080 [==============================] - 1s 631us/step - loss: 1.4016 - acc: 0.6537\n",
      "Epoch 1432/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.1069 - acc: 0.9657\n",
      "Epoch 1433/1500\n",
      "1080/1080 [==============================] - 1s 618us/step - loss: 0.0821 - acc: 0.9750\n",
      "Epoch 1434/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0644 - acc: 0.9824\n",
      "Epoch 1435/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0641 - acc: 0.9815\n",
      "Epoch 1436/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 0.0774 - acc: 0.9778\n",
      "Epoch 1437/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0628 - acc: 0.9815\n",
      "Epoch 1438/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.0577 - acc: 0.9824\n",
      "Epoch 1439/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0559 - acc: 0.9824\n",
      "Epoch 1440/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0578 - acc: 0.9824\n",
      "Epoch 1441/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0569 - acc: 0.9824 0s - loss: 0.0534 - acc: 0\n",
      "Epoch 1442/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0568 - acc: 0.9824\n",
      "Epoch 1443/1500\n",
      "1080/1080 [==============================] - 1s 664us/step - loss: 0.0575 - acc: 0.9824\n",
      "Epoch 1444/1500\n",
      "1080/1080 [==============================] - 1s 615us/step - loss: 0.0563 - acc: 0.9824\n",
      "Epoch 1445/1500\n",
      "1080/1080 [==============================] - 1s 669us/step - loss: 0.0561 - acc: 0.9824\n",
      "Epoch 1446/1500\n",
      "1080/1080 [==============================] - 1s 613us/step - loss: 0.0583 - acc: 0.9824\n",
      "Epoch 1447/1500\n",
      "1080/1080 [==============================] - 1s 635us/step - loss: 0.0554 - acc: 0.9824\n",
      "Epoch 1448/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0556 - acc: 0.9824\n",
      "Epoch 1449/1500\n",
      "1080/1080 [==============================] - 1s 654us/step - loss: 0.0541 - acc: 0.9824\n",
      "Epoch 1450/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0551 - acc: 0.9824\n",
      "Epoch 1451/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0559 - acc: 0.9824\n",
      "Epoch 1452/1500\n",
      "1080/1080 [==============================] - 1s 662us/step - loss: 0.0552 - acc: 0.9824\n",
      "Epoch 1453/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0555 - acc: 0.9824\n",
      "Epoch 1454/1500\n",
      "1080/1080 [==============================] - 1s 648us/step - loss: 0.0548 - acc: 0.9824\n",
      "Epoch 1455/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0555 - acc: 0.9824\n",
      "Epoch 1456/1500\n",
      "1080/1080 [==============================] - 1s 653us/step - loss: 0.0544 - acc: 0.9824\n",
      "Epoch 1457/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0582 - acc: 0.9824\n",
      "Epoch 1458/1500\n",
      "1080/1080 [==============================] - 1s 652us/step - loss: 0.0555 - acc: 0.9824\n",
      "Epoch 1459/1500\n",
      "1080/1080 [==============================] - 1s 641us/step - loss: 0.0601 - acc: 0.9824\n",
      "Epoch 1460/1500\n",
      "1080/1080 [==============================] - 1s 661us/step - loss: 0.0535 - acc: 0.9824\n",
      "Epoch 1461/1500\n",
      "1080/1080 [==============================] - 1s 647us/step - loss: 0.0548 - acc: 0.9824\n",
      "Epoch 1462/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0536 - acc: 0.9824\n",
      "Epoch 1463/1500\n",
      "1080/1080 [==============================] - 1s 637us/step - loss: 0.0544 - acc: 0.9824\n",
      "Epoch 1464/1500\n",
      "1080/1080 [==============================] - 1s 639us/step - loss: 0.0542 - acc: 0.9824\n",
      "Epoch 1465/1500\n",
      "1080/1080 [==============================] - 1s 672us/step - loss: 0.0543 - acc: 0.9824\n",
      "Epoch 1466/1500\n",
      "1080/1080 [==============================] - 1s 650us/step - loss: 0.0566 - acc: 0.9824\n",
      "Epoch 1467/1500\n",
      "1080/1080 [==============================] - 1s 621us/step - loss: 0.0779 - acc: 0.9759\n",
      "Epoch 1468/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0564 - acc: 0.9815\n",
      "Epoch 1469/1500\n",
      "1080/1080 [==============================] - 1s 645us/step - loss: 0.0553 - acc: 0.9824\n",
      "Epoch 1470/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.1777 - acc: 0.9417\n",
      "Epoch 1471/1500\n",
      "1080/1080 [==============================] - 1s 632us/step - loss: 1.0451 - acc: 0.7130\n",
      "Epoch 1472/1500\n",
      "1080/1080 [==============================] - 1s 649us/step - loss: 0.3800 - acc: 0.9000\n",
      "Epoch 1473/1500\n",
      "1080/1080 [==============================] - ETA: 0s - loss: 0.1302 - acc: 0.948 - 1s 662us/step - loss: 0.1385 - acc: 0.9426\n",
      "Epoch 1474/1500\n",
      "1080/1080 [==============================] - 1s 763us/step - loss: 0.1788 - acc: 0.9333\n",
      "Epoch 1475/1500\n",
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0675 - acc: 0.9815\n",
      "Epoch 1476/1500\n",
      "1080/1080 [==============================] - 1s 630us/step - loss: 0.0596 - acc: 0.9815\n",
      "Epoch 1477/1500\n",
      "1080/1080 [==============================] - 1s 627us/step - loss: 0.0576 - acc: 0.9824\n",
      "Epoch 1478/1500\n",
      "1080/1080 [==============================] - 1s 629us/step - loss: 0.0578 - acc: 0.9824\n",
      "Epoch 1479/1500\n",
      "1080/1080 [==============================] - 1s 646us/step - loss: 0.0571 - acc: 0.9824\n",
      "Epoch 1480/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0570 - acc: 0.9824\n",
      "Epoch 1481/1500\n",
      "1080/1080 [==============================] - 1s 712us/step - loss: 0.0552 - acc: 0.9824\n",
      "Epoch 1482/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0547 - acc: 0.9824\n",
      "Epoch 1483/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 1s 626us/step - loss: 0.0549 - acc: 0.9824\n",
      "Epoch 1484/1500\n",
      "1080/1080 [==============================] - 1s 611us/step - loss: 0.0548 - acc: 0.9824\n",
      "Epoch 1485/1500\n",
      "1080/1080 [==============================] - 1s 585us/step - loss: 0.0556 - acc: 0.9824\n",
      "Epoch 1486/1500\n",
      "1080/1080 [==============================] - 1s 640us/step - loss: 0.0563 - acc: 0.9824\n",
      "Epoch 1487/1500\n",
      "1080/1080 [==============================] - 1s 596us/step - loss: 0.0543 - acc: 0.9824\n",
      "Epoch 1488/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0541 - acc: 0.9824\n",
      "Epoch 1489/1500\n",
      "1080/1080 [==============================] - 1s 751us/step - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 1490/1500\n",
      "1080/1080 [==============================] - 1s 727us/step - loss: 0.0542 - acc: 0.9824 0s - loss: 0.0418 - acc: 0\n",
      "Epoch 1491/1500\n",
      "1080/1080 [==============================] - 1s 633us/step - loss: 0.0536 - acc: 0.9824 0s - loss: 0.0606 - acc: \n",
      "Epoch 1492/1500\n",
      "1080/1080 [==============================] - 1s 634us/step - loss: 0.0535 - acc: 0.9824\n",
      "Epoch 1493/1500\n",
      "1080/1080 [==============================] - 1s 657us/step - loss: 0.0537 - acc: 0.9824\n",
      "Epoch 1494/1500\n",
      "1080/1080 [==============================] - 1s 676us/step - loss: 0.0536 - acc: 0.9824\n",
      "Epoch 1495/1500\n",
      "1080/1080 [==============================] - 1s 668us/step - loss: 0.0543 - acc: 0.9824\n",
      "Epoch 1496/1500\n",
      "1080/1080 [==============================] - 1s 651us/step - loss: 0.0528 - acc: 0.9824\n",
      "Epoch 1497/1500\n",
      "1080/1080 [==============================] - 1s 663us/step - loss: 0.0523 - acc: 0.9824\n",
      "Epoch 1498/1500\n",
      "1080/1080 [==============================] - 1s 763us/step - loss: 0.0530 - acc: 0.9824\n",
      "Epoch 1499/1500\n",
      "1080/1080 [==============================] - 1s 713us/step - loss: 0.0529 - acc: 0.9824\n",
      "Epoch 1500/1500\n",
      "1080/1080 [==============================] - 1s 625us/step - loss: 0.0543 - acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a3e54d5b70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.T, Y_train.T, epochs=1500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 267us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0660067478815713, 0.775]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test.T,Y_test.T,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
