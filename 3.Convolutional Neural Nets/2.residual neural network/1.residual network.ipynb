{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建一个残差网络\n",
    "在残差网络中，一个“捷径（shortcut）”或者说“跳跃连接（skip connection）”允许梯度直接反向传播到更浅的层，如下图：\n",
    "<img src=\"images/20180509112530701.png\" style=\"width:650px;height:200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恒等块（Identity block）\n",
    "恒等块是残差网络使用的的标准块，对应于输入的激活值（比如$a^{[l]}$）与输出激活值（比如$a^{[l+1]}$）具有相同的维度。\n",
    "<img src=\"images/18.png\" style=\"width:650px;height:200px;\">\n",
    "上图中，上面的曲线路径是“捷径”，下面的直线路径是主路径。在上图中，我们依旧把CONV2D 与 ReLU包含到了每个步骤中，为了提升训练的速度，我们在每一步也把数据进行了归一化（BatchNorm）\n",
    "\n",
    "在实践中，我们要做一个更强大的版本：跳跃连接会跳过3个隐藏层而不是两个，就像下图： \n",
    "<img src=\"images/19.png\" style=\"width:650px;height:200px;\">\n",
    "每个步骤如下：\n",
    "\n",
    "主路径的第一部分：\n",
    "\n",
    "- 第一个CONV2D有$F_1$个过滤器，其大小为（1，1），步长为（1，1），使用填充方式为“valid”，命名规则为`conv_name_base + '2a'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第一个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2a'`。\n",
    "\n",
    "- 接着使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "主路径的第二部分：\n",
    "\n",
    "- 第二个CONV2D有$F_2$个过滤器，其大小为$(f,f)$ ，步长为（1，1），使用填充方式为“same”，命名规则为 `conv_name_base + '2b'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第二个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2b'`。\n",
    "\n",
    "- 接着使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "主路径的第三部分：\n",
    "\n",
    "- 第三个CONV2D有$F_3$个过滤器，其大小为（1，1），步长为（1，1），使用填充方式为“valid”，命名规则为`conv_name_base + '2c'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第三个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2c'`。\n",
    "\n",
    "- 注意这里没有ReLU函数\n",
    "\n",
    "最后一步：\n",
    "\n",
    "- 将捷径与输入加在一起\n",
    "\n",
    "- 使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "接下来我们就要实现残差网络的恒等块了，请务必查看下面的中文手册：\n",
    "- 实现Conv2D：[参见这里](https://keras.io/layers/convolutional/#conv2d)\n",
    "- 实现BatchNorm: [参见这里](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/) (axis: Integer, the axis that should be normalized (typically the channels axis))\n",
    "- 实现激活:  `Activation('relu')(X)`\n",
    "- 添加快捷方式传递的值: [参见这里](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    实现图3的恒等块\n",
    "\n",
    "    参数：\n",
    "        X - 输入的tensor类型的数据，维度为( m, n_H_prev, n_W_prev, n_H_prev )\n",
    "        f - 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters - 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage - 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block - 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "\n",
    "    返回：\n",
    "        X - 恒等块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "\n",
    "    #获取过滤器\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    #保存输入数据，将会用于为主路径添加捷径\n",
    "    X_shortcut = X\n",
    "\n",
    "    #主路径的第一部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1) ,padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    #主路径的第二部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f),strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "\n",
    "    #主路径的第三部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "    ##没有ReLU激活函数\n",
    "\n",
    "    #最后一步：\n",
    "    ##将捷径与输入加在一起\n",
    "    X = Add()([X,X_shortcut])\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积块\n",
    "我们已经实现了残差网络的恒等块，现在，残差网络的卷积块是另一种类型的残差块，它适用于输入输出的维度不一致的情况，它不同于上面的恒等块，与之区别在于，捷径中有一个CONV2D层，如下图：\n",
    "<img src=\"images/20.png\" style=\"width:650px;height:200px;\">\n",
    "\n",
    "捷径中的卷积层将把输入xx卷积为不同的维度，因此在主路径最后那里需要适配捷径中的维度。比如：把激活值中的宽高减少2倍，我们可以使用1x1的卷积，步伐为2。捷径上的卷积层不使用任何非线性激活函数，它的主要作用是仅仅应用（学习后的）线性函数来减少输入的维度，以便在后面的加法步骤中的维度相匹配。\n",
    "每个步骤如下：\n",
    "\n",
    "主路径的第一部分：\n",
    "\n",
    "- 第一个CONV2D有$F_1$个过滤器，其大小为（1，1），步长为（s，s），使用填充方式为“valid”，命名规则为`conv_name_base + '2a'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第一个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2a'`。\n",
    "\n",
    "- 接着使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "主路径的第二部分：\n",
    "\n",
    "- 第二个CONV2D有$F_2$个过滤器，其大小为$(f,f)$ ，步长为（1，1），使用填充方式为“same”，命名规则为 `conv_name_base + '2b'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第二个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2b'`。\n",
    "\n",
    "- 接着使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "主路径的第三部分：\n",
    "\n",
    "- 第三个CONV2D有$F_3$个过滤器，其大小为（1，1），步长为（1，1），使用填充方式为“valid”，命名规则为`conv_name_base + '2c'`，使用0作为随机种子为其初始化。\n",
    "\n",
    "- 第三个BatchNorm是通道的轴归一化，其命名规则为`bn_name_base + '2c'`。\n",
    "\n",
    "- 注意这里没有ReLU函数\n",
    "\n",
    "捷径：\n",
    "\n",
    "- 此卷积层有$F_3$个过滤器，其维度为（1，1），步伐为（s，s），使用“valid”的填充方式，命名规则为`conv_name_base + '1'`\n",
    "\n",
    "- 此规范层是通道的轴归一化，其命名规则为 `bn_name_base + '1'`\n",
    "\n",
    "最后一步：\n",
    "\n",
    "- 将捷径与输入加在一起\n",
    "\n",
    "- 使用ReLU激活函数，它没有命名也没有超参数。\n",
    "\n",
    "接下来我们就要实现残差网络的恒等块了，请务必查看下面的中文手册：\n",
    "- 实现Conv2D：[参见这里](https://keras.io/layers/convolutional/#conv2d)\n",
    "- 实现BatchNorm: [参见这里](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/) (axis: Integer, the axis that should be normalized (typically the channels axis))\n",
    "- 实现激活:  `Activation('relu')(X)`\n",
    "- 添加快捷方式传递的值: [参见这里](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    实现图5的卷积块\n",
    "\n",
    "    参数：\n",
    "        X - 输入的tensor类型的变量，维度为( m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f - 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters - 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage - 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block - 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "        s - 整数，指定要使用的步幅\n",
    "\n",
    "    返回：\n",
    "        X - 卷积块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "\n",
    "    #获取过滤器数量\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    #保存输入数据\n",
    "    X_shortcut = X\n",
    "\n",
    "    #主路径\n",
    "    ##主路径第一部分\n",
    "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    ##主路径第二部分\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    ##主路径第三部分\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "\n",
    "    #捷径\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"1\", kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3,name=bn_name_base+\"1\")(X_shortcut)\n",
    "\n",
    "    #最后一步\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建残差网络（50层）\n",
    "\n",
    "我们已经做完所需要的所有残差块了，下面这个图就描述了神经网络的算法细节，图中的”ID BLOCK“是指标准的恒等块，”ID BLOCK X3“是指把三个恒等块放在一起。 \n",
    "<img src=\"images/21.png\" style=\"width:650px;height:200px;\">\n",
    "\n",
    "这个50层的网络的细节如下: \n",
    "- 对输入数据进行0填充，padding =（3,3）\n",
    "\n",
    "- stage1：\n",
    "\n",
    "    - 卷积层有64个过滤器，其维度为（7，7），步伐为（2，2），命名为“conv1”\n",
    "\n",
    "    - 规范层（BatchNorm）对输入数据进行通道轴归一化。\n",
    "\n",
    "    - 最大值池化层使用一个（3，3）的窗口和（2，2）的步伐。\n",
    "\n",
    "- stage2：\n",
    "\n",
    "    - 卷积块使用f=3个大小为[64，64，256]的过滤器，f=3，s=1,block=”a”\n",
    "\n",
    "    - 2个恒等块使用三个大小为[64，64，256]的过滤器，f=3，block=”b”、”c”\n",
    "\n",
    "- stage3：\n",
    "\n",
    "    - 卷积块使用f=3个大小为[128,128,512]的过滤器，f=3，s=2,block=”a”\n",
    "\n",
    "    - 3个恒等块使用三个大小为[128,128,512]的过滤器，f=3，block=”b”、”c”、”d”\n",
    "\n",
    "- stage4：\n",
    "\n",
    "    - 卷积块使用f=3个大小为[256,256,1024]的过滤器，f=3，s=2,block=”a”\n",
    "\n",
    "    - 5个恒等块使用三个大小为[256,256,1024]的过滤器，f=3，block=”b”、”c”、”d”、”e”、”f”\n",
    "\n",
    "- stage5：\n",
    "\n",
    "    - 卷积块使用f=3个大小为[512,512,2048]的过滤器，f=3，s=2,block=”a”\n",
    "\n",
    "    - 2个恒等块使用三个大小为[256,256,2048]的过滤器，f=3，block=”b”、”c”\n",
    "\n",
    "- 均值池化层使用维度为（2,2）的窗口，命名为“avg_pool”\n",
    "\n",
    "- 展开操作没有任何超参数以及命名\n",
    "- 全连接层（密集连接）使用softmax激活函数，命名为\"fc\" + str(classes)\n",
    "\n",
    "为了实现这50层的残差网络，我们需要查看一下手册：\n",
    "\n",
    "- 均值池化层：[参见这里](https://keras.io/layers/pooling/#averagepooling2d)\n",
    "\n",
    "- Conv2D： [参见这里](https://keras.io/layers/convolutional/#conv2d)\n",
    "- BatchNorm:  [参见这里](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, the axis that should be normalized (typically the features axis))\n",
    "\n",
    "- 0填充：[参见这里](https://keras.io/layers/convolutional/#zeropadding2d)\n",
    "\n",
    "- 最大值池化层： [参见这里](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "\n",
    "- 全连接层： [参见这里](https://keras.io/layers/core/#dense)\n",
    "\n",
    "- 添加快捷方式传递的值：[参见这里](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(64,64,3),classes=6):\n",
    "    \"\"\"\n",
    "    实现ResNet50\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    参数：\n",
    "        input_shape - 图像数据集的维度\n",
    "        classes - 整数，分类数\n",
    "\n",
    "    返回：\n",
    "        model - Keras框架的模型\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #定义tensor类型的输入数据\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    #0填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "    #stage1\n",
    "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "\n",
    "    #stage2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "\n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "\n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "\n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "\n",
    "    #均值池化层\n",
    "    X = AveragePooling2D(pool_size=(2,2),padding=\"same\")(X)\n",
    "\n",
    "    #输出层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    #创建模型\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对模型做实体化和编译工作：\n",
    "model = ResNet50(input_shape=(64,64,3),classes=6)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/22.png\" style=\"width:650px;height:200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = resnets_utils.load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = resnets_utils.convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1080/1080 [==============================] - 266s 247ms/step - loss: 0.7320 - acc: 0.8519\n",
      "Epoch 2/100\n",
      "1080/1080 [==============================] - 265s 245ms/step - loss: 0.4354 - acc: 0.9278\n",
      "Epoch 3/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.3456 - acc: 0.9704\n",
      "Epoch 4/100\n",
      "1080/1080 [==============================] - 287s 266ms/step - loss: 0.4127 - acc: 0.9657\n",
      "Epoch 5/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.4008 - acc: 0.9565\n",
      "Epoch 6/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.3688 - acc: 0.9602\n",
      "Epoch 7/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.2731 - acc: 0.9713\n",
      "Epoch 8/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.2735 - acc: 0.9537\n",
      "Epoch 9/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.3311 - acc: 0.9259\n",
      "Epoch 10/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.8363 - acc: 0.8111\n",
      "Epoch 11/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.7856 - acc: 0.8389\n",
      "Epoch 12/100\n",
      "1080/1080 [==============================] - 272s 252ms/step - loss: 0.6574 - acc: 0.8685\n",
      "Epoch 13/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.5104 - acc: 0.9167\n",
      "Epoch 14/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.4565 - acc: 0.9324\n",
      "Epoch 15/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.4401 - acc: 0.9250\n",
      "Epoch 16/100\n",
      "1080/1080 [==============================] - 278s 258ms/step - loss: 0.3020 - acc: 0.9463\n",
      "Epoch 17/100\n",
      "1080/1080 [==============================] - 272s 252ms/step - loss: 0.2428 - acc: 0.9583\n",
      "Epoch 18/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.6532 - acc: 0.8898\n",
      "Epoch 19/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.6226 - acc: 0.8583\n",
      "Epoch 20/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.3119 - acc: 0.9259\n",
      "Epoch 21/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.2431 - acc: 0.9602\n",
      "Epoch 22/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.2127 - acc: 0.9750\n",
      "Epoch 23/100\n",
      "1080/1080 [==============================] - 271s 251ms/step - loss: 0.1740 - acc: 0.9787\n",
      "Epoch 24/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 1.0612 - acc: 0.7611\n",
      "Epoch 25/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.5703 - acc: 0.8815\n",
      "Epoch 26/100\n",
      "1080/1080 [==============================] - 271s 250ms/step - loss: 0.3880 - acc: 0.9074\n",
      "Epoch 27/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.2096 - acc: 0.9417\n",
      "Epoch 28/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.1888 - acc: 0.9463\n",
      "Epoch 29/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.2102 - acc: 0.9620\n",
      "Epoch 30/100\n",
      "1080/1080 [==============================] - 272s 251ms/step - loss: 0.2033 - acc: 0.9657\n",
      "Epoch 31/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.3069 - acc: 0.9435\n",
      "Epoch 32/100\n",
      "1080/1080 [==============================] - 272s 252ms/step - loss: 0.2396 - acc: 0.9528\n",
      "Epoch 33/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.1423 - acc: 0.9750\n",
      "Epoch 34/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.1083 - acc: 0.9898\n",
      "Epoch 35/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.1015 - acc: 0.9926\n",
      "Epoch 36/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.1941 - acc: 0.9852\n",
      "Epoch 37/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.4446 - acc: 0.9630\n",
      "Epoch 38/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.8436 - acc: 0.8194\n",
      "Epoch 39/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 1.1759 - acc: 0.7028\n",
      "Epoch 40/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.6770 - acc: 0.8426\n",
      "Epoch 41/100\n",
      "1080/1080 [==============================] - 274s 254ms/step - loss: 0.3797 - acc: 0.9083\n",
      "Epoch 42/100\n",
      "1080/1080 [==============================] - 280s 259ms/step - loss: 0.1718 - acc: 0.9500\n",
      "Epoch 43/100\n",
      "1080/1080 [==============================] - 274s 253ms/step - loss: 0.1089 - acc: 0.9741\n",
      "Epoch 44/100\n",
      "1080/1080 [==============================] - 277s 257ms/step - loss: 0.0655 - acc: 0.9852\n",
      "Epoch 45/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.0422 - acc: 0.9926\n",
      "Epoch 46/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0322 - acc: 0.9935\n",
      "Epoch 47/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 48/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0231 - acc: 0.9935\n",
      "Epoch 49/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0170 - acc: 0.9954\n",
      "Epoch 50/100\n",
      "1080/1080 [==============================] - 274s 254ms/step - loss: 0.0176 - acc: 0.9944\n",
      "Epoch 51/100\n",
      "1080/1080 [==============================] - 273s 253ms/step - loss: 0.0295 - acc: 0.9907\n",
      "Epoch 52/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0197 - acc: 0.9944\n",
      "Epoch 53/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0173 - acc: 0.9944\n",
      "Epoch 54/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0068 - acc: 0.9991\n",
      "Epoch 55/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0075 - acc: 0.9972\n",
      "Epoch 56/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0182 - acc: 0.9972\n",
      "Epoch 57/100\n",
      "1080/1080 [==============================] - 271s 251ms/step - loss: 0.0377 - acc: 0.9852\n",
      "Epoch 58/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0450 - acc: 0.9852\n",
      "Epoch 59/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0366 - acc: 0.9926\n",
      "Epoch 60/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 61/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1080/1080 [==============================] - 271s 251ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 6.1575e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 7.4054e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1080/1080 [==============================] - 271s 251ms/step - loss: 3.5245e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 7.9015e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 6.1855e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 4.0155e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 4.4293e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 76/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 5.9448e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 4.2332e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 3.9603e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 8.1867e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 4.6021e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 5.9024e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 2.0208e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 4.5759e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 5.6268e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 8.1239e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 1.5448e-04 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0300 - acc: 0.9963\n",
      "Epoch 88/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0041 - acc: 0.9991\n",
      "Epoch 90/100\n",
      "1080/1080 [==============================] - 269s 249ms/step - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 91/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1080/1080 [==============================] - 267s 248ms/step - loss: 5.7662e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 4.7097e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 7.5493e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0246 - acc: 0.9981\n",
      "Epoch 96/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0107 - acc: 0.9981\n",
      "Epoch 97/100\n",
      "1080/1080 [==============================] - 270s 250ms/step - loss: 0.0155 - acc: 0.9935\n",
      "Epoch 98/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0104 - acc: 0.9954\n",
      "Epoch 99/100\n",
      "1080/1080 [==============================] - 268s 248ms/step - loss: 0.0201 - acc: 0.9944\n",
      "Epoch 100/100\n",
      "1080/1080 [==============================] - 268s 249ms/step - loss: 0.0249 - acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x184afa57c88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('res.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Res.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 78s 650ms/step\n",
      "误差值 = 0.12439964612325033\n",
      "准确率 = 0.949999996026357\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test,Y_test)\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9931860e-01 7.0890437e-08 2.0107608e-04 4.7210135e-04 7.8064013e-06\n",
      "  2.5613858e-07]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#测试自己的图片\n",
    "img_path = 'finger.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bf56bbf9f76a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         raise OSError(\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
